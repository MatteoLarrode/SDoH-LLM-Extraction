python scripts/llama/multilabel_direct/train.py \
  --train_data_file data/processed/train-test/train_set.csv \
  --val_data_file data/processed/train-test/val_set.csv \
  --learning_rate 9e-5 \
  --per_device_train_batch_size 8 \
  --per_device_eval_batch_size 8 \
  --num_train_epochs 6

python scripts/llama/multi_label_full/eval.py \
  --test_data_file data/processed/train-test/test_set.csv \
  --model_dir results/model_training/llama_multilabel_direct/Llama-3.1-8B-Instruct_bs8_lr9e-05_epochs6_20250710_164937 \
  --head

python scripts/llama/multi_label_full/eval.py \
  --test_data_file data/processed/train-test/test_set.csv \
  --model_dir results/model_training/llama_multilabel_direct/Llama-3.1-8B-Instruct_bs8_lr9e-05_epochs6_20250710_164937

#### Traing and Eval with result of the random search ####
python scripts/llama/multilabel_direct/train.py \
--train_data_file data/processed/train-test/train_set.csv \
--val_data_file data/processed/train-test/val_set.csv \
--r 8 \
--lora_alpha 64 \
--lora_dropout 0 \
--learning_rate 3e-5 \
--num_train_epochs 6 \
--per_device_train_batch_size 4 \
--model_output_base results/model_training/llama_multilabel_direct/best_model

python scripts/llama/multilabel_direct/eval.py \
  --test_data_file data/processed/train-test/test_set.csv \
  --model_dir results/model_training/llama_multilabel_direct/best_model/Llama-3.1-8B-Instruct_bs4_lr3e-05_epochs6_20250727_014117