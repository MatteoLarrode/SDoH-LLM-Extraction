{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d71a71a",
   "metadata": {},
   "source": [
    "# Few-shot Classifiction of SDoH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f133f46",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51994ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb2a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1860d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Use shared cache\n",
    "os.environ['HF_HOME'] = '/data/resource/huggingface'\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'  # Force offline mode\n",
    "\n",
    "# What models are available\n",
    "cache_dir = \"/data/resource/huggingface/hub\"\n",
    "available_models = []\n",
    "\n",
    "# Suppress warnings from transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b75ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "brc_referrals_cleaned = pd.read_csv(\"../data/processed/brc-cleaned/referrals_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c7cf8",
   "metadata": {},
   "source": [
    "## 1. Few-shot classification of SDoH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1461c3e",
   "metadata": {},
   "source": [
    "### 1.1 Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b3ed5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cached models:\n",
      "  CohereForAI/aya-23-35B\n",
      "  CohereForAI/aya-23-8B\n",
      "  CohereForAI/aya-vision-8b\n",
      "  HuggingFaceTB/SmolLM-135M-Instruct\n",
      "  LLaMAX/LLaMAX3-8B-Alpaca\n",
      "  Qwen/Qwen1.5-4B\n",
      "  Qwen/Qwen2-7B\n",
      "  Qwen/Qwen2.5-1.5B\n",
      "  Qwen/Qwen2.5-3B\n",
      "  Qwen/Qwen2.5-72B-Instruct\n",
      "  Qwen/Qwen2.5-7B\n",
      "  Qwen/Qwen2.5-7B-Instruct\n",
      "  Qwen/Qwen2.5-7B-instruct\n",
      "  Qwen/Qwen2.5-VL-7B-Instruct\n",
      "  Qwen/Qwen3-0.6B\n",
      "  Qwen/Qwen3-8B\n",
      "  Unbabel/wmt20-comet-qe-da\n",
      "  Unbabel/wmt22-comet-da\n",
      "  bert-base-uncased\n",
      "  bert-large-uncased\n",
      "  cardiffnlp/twitter-roberta-base-sentiment\n",
      "  clairebarale/refugee_cases_ner\n",
      "  cross-encoder/stsb-roberta-base\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n",
      "  facebook/nllb-200-3.3B\n",
      "  facebook/nllb-200-distilled-1.3B\n",
      "  facebook/nllb-200-distilled-600M\n",
      "  google/gemma-3-1b-it\n",
      "  google/gemma-3-27b-it\n",
      "  google/gemma-3-27b-it-qat-q4_0-gguf\n",
      "  gpt2\n",
      "  gpt2-medium\n",
      "  gpt2-xl\n",
      "  hfl/chinese-bert-wwm\n",
      "  hfl/chinese-electra-180g-small-discriminator\n",
      "  hfl/chinese-legal-electra-base-discriminator\n",
      "  hfl/chinese-legal-electra-small-discriminator\n",
      "  hfl/chinese-roberta-wwm-ext\n",
      "  hfl/chinese-roberta-wwm-ext-large\n",
      "  jxm/gtr__nq__32\n",
      "  jxm/gtr__nq__32__correct\n",
      "  meta-llama/Llama-2-7b-chat-hf\n",
      "  meta-llama/Llama-2-7b-hf\n",
      "  meta-llama/Llama-3.1-70B-Instruct\n",
      "  meta-llama/Llama-3.1-8B\n",
      "  meta-llama/Llama-3.1-8B-Instruct\n",
      "  meta-llama/Llama-3.2-11B-Vision-Instruct\n",
      "  meta-llama/Llama-3.3-70B-Instruct\n",
      "  meta-llama/Llama-4-Scout-17B-16E\n",
      "  meta-llama/Meta-Llama-3-70B-Instruct\n",
      "  meta-llama/Meta-Llama-3-8B\n",
      "  meta-llama/Meta-Llama-3-8B-Instruct\n",
      "  meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "  microsoft/Phi-3-mini-4k-instruct\n",
      "  microsoft/Phi-3.5-vision-instruct\n",
      "  microsoft/Phi-4-mini-instruct\n",
      "  microsoft/Phi-4-multimodal-instruct\n",
      "  microsoft/deberta-large-mnli\n",
      "  microsoft/deberta-v3-base\n",
      "  microsoft/deberta-xlarge\n",
      "  microsoft/deberta-xlarge-mnli\n",
      "  mistral-community/pixtral-12b\n",
      "  mistralai/Mistral-7B-Instruct-v0.2\n",
      "  mistralai/Mistral-7B-Instruct-v0.3\n",
      "  mistralai/Mistral-7B-v0.1\n",
      "  mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "  mosaicml/mpt-7b-chat\n",
      "  nlpaueb/legal-bert-base-uncased\n",
      "  nvidia/Llama-3.1-Nemotron-Nano-8B-v1\n",
      "  openai-community/gpt2\n",
      "  openai-community/gpt2-medium\n",
      "  openai-community/gpt2-xl\n",
      "  openai/whisper-large-v3-turbo\n",
      "  openbmb/MiniCPM-o-2_6\n",
      "  roberta-base\n",
      "  roberta-large\n",
      "  saibo/legal-roberta-base\n",
      "  sentence-transformers/LaBSE\n",
      "  sentence-transformers/all-MPNet-base-v2\n",
      "  sentence-transformers/all-MiniLM-L6-v2\n",
      "  sentence-transformers/all-mpnet-base-v2\n",
      "  sentence-transformers/gtr-t5-base\n",
      "  sentence-transformers/msmarco-bert-co-condensor\n",
      "  sentence-transformers/paraphrase-distilroberta-base-v2\n",
      "  sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "  sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
      "  shibing624/text2vec-base-chinese\n",
      "  t5-base\n",
      "  t5-large\n",
      "  t5-small\n",
      "  vahidthegreat/StanceAware-SBERT\n",
      "  xlm-roberta-base\n",
      "  xlm-roberta-large\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(cache_dir):\n",
    "    for item in os.listdir(cache_dir):\n",
    "        if item.startswith(\"models--\"):\n",
    "            # Convert models--org--name to org/name format\n",
    "            model_name = item.replace(\"models--\", \"\").replace(\"--\", \"/\")\n",
    "            available_models.append(model_name)\n",
    "\n",
    "print(\"Available cached models:\")\n",
    "for model in sorted(available_models):\n",
    "    print(f\"  {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c75c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.52.3\n",
      "PyTorch version: 2.6.0\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6ca370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta-llama/Llama-3.1-8B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07a1b68e57c4a539b5c4459c69e4c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ meta-llama/Llama-3.1-8B-Instruct loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load one of the instruction-tuned models\n",
    "# Qwen/Qwen2.5-7B-Instruct\n",
    "# meta-llama/Llama-3.1-8B-Instruct\n",
    "# microsoft/Phi-4-mini-instruct\n",
    "# mistralai/Mistral-7B-Instruct-v0.3\n",
    "\n",
    "from src.classification.model_helpers import load_instruction_model\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer, model = None, None\n",
    "\n",
    "tokenizer, model = load_instruction_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423c8c5",
   "metadata": {},
   "source": [
    "### 1.2 Extraction from one note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f573d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a specific note: Case Reference = CAS-467812\n",
    "sample_note = brc_referrals_cleaned[brc_referrals_cleaned['Case Reference'] == 'CAS-467812'].iloc[0]['Referral Notes (depersonalised)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a907ccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Example Prompt (Five Shot Basic):\n",
      "==================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are analyzing a referral note sentence to identify Social Determinants of Health, and classifying them as Adverse or Protective.\n",
      "\n",
      "Given a sentence, output all SDoH factors that can be inferred from that sentence from the following list: \n",
      "Loneliness, Housing, Finances, FoodAccess, Digital, Employment, EnglishProficiency.\n",
      "\n",
      "Each SDoH must be classified as either \"Adverse\" or \"Protective\". \n",
      "If the sentence does NOT mention any of the above categories, output <LIST>NoSDoH</LIST>.\n",
      "\n",
      "Your response must be a comma-separated list of SDoH-Polarity pairs embedded in <LIST> and </LIST> tags.\n",
      "\n",
      "**STRICT RULES**:\n",
      "- DO NOT generate any other text, explanations, or new SDoH labels.\n",
      "- A sentence CAN be labeled with one or more SDoH factors.\n",
      "- The only accepted format is <LIST>...</LIST>.\n",
      "\n",
      "EXAMPLES:\n",
      "Input: \"She is unemployed and struggles to pay rent.\"\n",
      "Output: <LIST>Employment-Adverse, Finances-Adverse, Housing-Adverse</LIST>\n",
      "\n",
      "Input: \"We are referring the above patient to you today for befriending.\"\n",
      "Output: <LIST>Loneliness-Adverse</LIST>\n",
      "\n",
      "Input: \"She enjoys a strong network of friends and volunteers weekly.\"\n",
      "Output: <LIST>Loneliness-Protective</LIST>\n",
      "\n",
      "Input: \"Sleeping at a friend's for now.\"\n",
      "Output: <LIST>Housing-Adverse</LIST>\n",
      "\n",
      "Input: \"Cannot take public transport to do groceries.\"\n",
      "Output: <LIST>FoodAccess-Adverse</LIST>\n",
      "\n",
      "Input: \"Daughter translates at GP visits.\"\n",
      "Output: <LIST>EnglishProficiency-Adverse</LIST><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input: \"This is a sentence\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.classification.prompt_creation_helpers import create_automated_prompt\n",
    "\n",
    "prompt_example_basic = create_automated_prompt(\"This is a sentence\", tokenizer=tokenizer, prompt_type=\"five_shot_basic\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Example Prompt (Five Shot Basic):\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt_example_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f19121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted SDoH Factors:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "note_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "has_sdoh",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "sdoh_factors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_sdoh_factors",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "86dbbbbb-7b46-44f4-b553-58fe6ee22414",
       "rows": [
        [
         "0",
         "sample",
         "1",
         "Lives with husband for whom patient is carer",
         "True",
         "Housing-Protective, Employment-Adverse",
         "2"
        ],
        [
         "1",
         "sample",
         "2",
         "Living on ready meals at present",
         "True",
         "FoodAccess-Adverse",
         "1"
        ],
        [
         "2",
         "sample",
         "3",
         "[PERSON] concerned that they may not be eating / drinking enough",
         "True",
         "FoodAccess-Adverse",
         "1"
        ],
        [
         "3",
         "sample",
         "4",
         "Carers in [REDACTED] times daily for patient to help with washing / dressing",
         "True",
         "Housing-Protective, Employment-Adverse",
         "2"
        ],
        [
         "4",
         "sample",
         "5",
         "Depending on side - effects of radiotherapy , patient may go on to PEG feeding",
         "True",
         "FoodAccess-Adverse",
         "1"
        ],
        [
         "5",
         "sample",
         "6",
         "Patient feeling slightly overwhelmed by everything",
         "True",
         "Loneliness-Adverse",
         "1"
        ],
        [
         "6",
         "sample",
         "7",
         "FPOC and Carers Support Shropshire numbers given to patient ’s daughter ( with patient consent ) but would value additional emotional support / befriending / check ins to make sure they are eating / drinking etc as all activities of daily living severely compromised at present",
         "True",
         "Loneliness-Adverse, Finances-NoSDoH, Housing-NoSDoH, FoodAccess-Adverse, Employment-NoSDoH, EnglishProficiency-NoSDoH",
         "6"
        ],
        [
         "7",
         "sample",
         "8",
         "Very supportive daughter who lives in [PERSON]",
         "True",
         "Loneliness-Protective, Housing-Adverse",
         "2"
        ],
        [
         "8",
         "sample",
         "9",
         "The patient is due to start radiotherapy on [REDACTED] January so support during this time would be particularly beneficial",
         "False",
         "NoSDoH",
         "0"
        ],
        [
         "9",
         "sample",
         "10",
         "Due to start radiotherapy on [REDACTED] at SATH EOS [REDACTED]",
         "False",
         "NoSDoH",
         "0"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_sdoh</th>\n",
       "      <th>sdoh_factors</th>\n",
       "      <th>num_sdoh_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "      <td>Lives with husband for whom patient is carer</td>\n",
       "      <td>True</td>\n",
       "      <td>Housing-Protective, Employment-Adverse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample</td>\n",
       "      <td>2</td>\n",
       "      <td>Living on ready meals at present</td>\n",
       "      <td>True</td>\n",
       "      <td>FoodAccess-Adverse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample</td>\n",
       "      <td>3</td>\n",
       "      <td>[PERSON] concerned that they may not be eating...</td>\n",
       "      <td>True</td>\n",
       "      <td>FoodAccess-Adverse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample</td>\n",
       "      <td>4</td>\n",
       "      <td>Carers in [REDACTED] times daily for patient t...</td>\n",
       "      <td>True</td>\n",
       "      <td>Housing-Protective, Employment-Adverse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample</td>\n",
       "      <td>5</td>\n",
       "      <td>Depending on side - effects of radiotherapy , ...</td>\n",
       "      <td>True</td>\n",
       "      <td>FoodAccess-Adverse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample</td>\n",
       "      <td>6</td>\n",
       "      <td>Patient feeling slightly overwhelmed by everyt...</td>\n",
       "      <td>True</td>\n",
       "      <td>Loneliness-Adverse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample</td>\n",
       "      <td>7</td>\n",
       "      <td>FPOC and Carers Support Shropshire numbers giv...</td>\n",
       "      <td>True</td>\n",
       "      <td>Loneliness-Adverse, Finances-NoSDoH, Housing-N...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample</td>\n",
       "      <td>8</td>\n",
       "      <td>Very supportive daughter who lives in [PERSON]</td>\n",
       "      <td>True</td>\n",
       "      <td>Loneliness-Protective, Housing-Adverse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample</td>\n",
       "      <td>9</td>\n",
       "      <td>The patient is due to start radiotherapy on [R...</td>\n",
       "      <td>False</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample</td>\n",
       "      <td>10</td>\n",
       "      <td>Due to start radiotherapy on [REDACTED] at SAT...</td>\n",
       "      <td>False</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  note_id  sentence_number                                           sentence  \\\n",
       "0  sample                1       Lives with husband for whom patient is carer   \n",
       "1  sample                2                   Living on ready meals at present   \n",
       "2  sample                3  [PERSON] concerned that they may not be eating...   \n",
       "3  sample                4  Carers in [REDACTED] times daily for patient t...   \n",
       "4  sample                5  Depending on side - effects of radiotherapy , ...   \n",
       "5  sample                6  Patient feeling slightly overwhelmed by everyt...   \n",
       "6  sample                7  FPOC and Carers Support Shropshire numbers giv...   \n",
       "7  sample                8     Very supportive daughter who lives in [PERSON]   \n",
       "8  sample                9  The patient is due to start radiotherapy on [R...   \n",
       "9  sample               10  Due to start radiotherapy on [REDACTED] at SAT...   \n",
       "\n",
       "   has_sdoh                                       sdoh_factors  \\\n",
       "0      True             Housing-Protective, Employment-Adverse   \n",
       "1      True                                 FoodAccess-Adverse   \n",
       "2      True                                 FoodAccess-Adverse   \n",
       "3      True             Housing-Protective, Employment-Adverse   \n",
       "4      True                                 FoodAccess-Adverse   \n",
       "5      True                                 Loneliness-Adverse   \n",
       "6      True  Loneliness-Adverse, Finances-NoSDoH, Housing-N...   \n",
       "7      True             Loneliness-Protective, Housing-Adverse   \n",
       "8     False                                             NoSDoH   \n",
       "9     False                                             NoSDoH   \n",
       "\n",
       "   num_sdoh_factors  \n",
       "0                 2  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 2  \n",
       "4                 1  \n",
       "5                 1  \n",
       "6                 6  \n",
       "7                 2  \n",
       "8                 0  \n",
       "9                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.classification.SDoH_classification_helpers import SDoHExtractor\n",
    "\n",
    "# Initialize the SDoH extractor\n",
    "extractor = SDoHExtractor(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt_type=\"five_shot_basic\",\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "# Extract SDoH factors\n",
    "results = extractor.extract_from_note(sample_note)\n",
    "results_df = extractor.results_to_dataframe(results, note_id=\"sample\")\n",
    "\n",
    "print(\"\\nExtracted SDoH Factors:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c42d5832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "note_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "has_sdoh",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "sdoh_factors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "num_sdoh_factors",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "dedbd937-25e1-4c8a-b64a-1c4d87abeb40",
       "rows": [
        [
         "0",
         "sample",
         "1",
         "Lives with husband for whom patient is carer",
         "True",
         "Housing-Protective, Employment-Adverse",
         "2"
        ],
        [
         "1",
         "sample",
         "2",
         "Living on ready meals at present",
         "True",
         "FoodAccess-Adverse",
         "1"
        ],
        [
         "2",
         "sample",
         "3",
         "[PERSON] concerned that they may not be eating / drinking enough",
         "True",
         "FoodAccess-Adverse",
         "1"
        ],
        [
         "3",
         "sample",
         "4",
         "Carers in [REDACTED] times daily for patient to help with washing / dressing",
         "True",
         "Housing-Protective, Employment-Adverse",
         "2"
        ],
        [
         "4",
         "sample",
         "5",
         "Depending on side - effects of radiotherapy , patient may go on to PEG feeding",
         "True",
         "FoodAccess-Adverse",
         "1"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>sentence</th>\n",
       "      <th>has_sdoh</th>\n",
       "      <th>sdoh_factors</th>\n",
       "      <th>num_sdoh_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "      <td>Lives with husband for whom patient is carer</td>\n",
       "      <td>True</td>\n",
       "      <td>Housing-Protective, Employment-Adverse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample</td>\n",
       "      <td>2</td>\n",
       "      <td>Living on ready meals at present</td>\n",
       "      <td>True</td>\n",
       "      <td>FoodAccess-Adverse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample</td>\n",
       "      <td>3</td>\n",
       "      <td>[PERSON] concerned that they may not be eating...</td>\n",
       "      <td>True</td>\n",
       "      <td>FoodAccess-Adverse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample</td>\n",
       "      <td>4</td>\n",
       "      <td>Carers in [REDACTED] times daily for patient t...</td>\n",
       "      <td>True</td>\n",
       "      <td>Housing-Protective, Employment-Adverse</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample</td>\n",
       "      <td>5</td>\n",
       "      <td>Depending on side - effects of radiotherapy , ...</td>\n",
       "      <td>True</td>\n",
       "      <td>FoodAccess-Adverse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  note_id  sentence_number                                           sentence  \\\n",
       "0  sample                1       Lives with husband for whom patient is carer   \n",
       "1  sample                2                   Living on ready meals at present   \n",
       "2  sample                3  [PERSON] concerned that they may not be eating...   \n",
       "3  sample                4  Carers in [REDACTED] times daily for patient t...   \n",
       "4  sample                5  Depending on side - effects of radiotherapy , ...   \n",
       "\n",
       "   has_sdoh                            sdoh_factors  num_sdoh_factors  \n",
       "0      True  Housing-Protective, Employment-Adverse                 2  \n",
       "1      True                      FoodAccess-Adverse                 1  \n",
       "2      True                      FoodAccess-Adverse                 1  \n",
       "3      True  Housing-Protective, Employment-Adverse                 2  \n",
       "4      True                      FoodAccess-Adverse                 1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some debugging\n",
    "print(\"Prompt: \\n\")\n",
    "print(results['sentences'][1]['debug']['prompt'])\n",
    "\n",
    "print(\"Raw response: \\n\")\n",
    "print(results['sentences'][1]['debug']['raw_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016e3df",
   "metadata": {},
   "source": [
    "### 1.3. Extracting from multiple notes (batch processing) and evaluating few-shot extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edaf5afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta-llama/Llama-3.1-8B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1602a9a063aa4dc8b462292ffb9ed9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ meta-llama/Llama-3.1-8B-Instruct loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set desired model and prompt config\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "PROMPT_TYPE = \"five_shot_basic\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "from src.classification.model_helpers import load_instruction_model\n",
    "from src.classification.SDoH_classification_helpers import SDoHExtractor\n",
    "\n",
    "tokenizer, model = load_instruction_model(MODEL_NAME)\n",
    "\n",
    "# Confirm it's loaded\n",
    "if tokenizer is None or model is None:\n",
    "    raise ValueError(f\"Failed to load model: {MODEL_NAME}\")\n",
    "\n",
    "# Create extractor using your standard constructor\n",
    "extractor = SDoHExtractor(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt_type=PROMPT_TYPE,\n",
    "    debug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "322a6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Step 1: Load test set ===\n",
    "test_df = pd.read_csv(\"../data/processed/train-test/test_set.csv\")\n",
    "test_df[\"label_pair\"] = test_df[\"label_pair\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "266ac322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [02:17<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "      Digital-Adverse       0.40      0.67      0.50         6\n",
      "   Digital-Protective       0.00      0.00      0.00         1\n",
      "   Employment-Adverse       0.17      1.00      0.29         3\n",
      "Employment-Protective       0.00      0.00      0.00         1\n",
      "      English-Adverse       0.00      0.00      0.00         2\n",
      "     Finances-Adverse       0.38      0.82      0.52        17\n",
      "  Finances-Protective       0.00      0.00      0.00         1\n",
      "         Food-Adverse       0.00      0.00      0.00        20\n",
      "      Food-Protective       0.00      0.00      0.00         1\n",
      "      Housing-Adverse       0.44      0.71      0.55        28\n",
      "   Housing-Protective       0.12      1.00      0.22         1\n",
      "   Loneliness-Adverse       0.57      0.69      0.63        39\n",
      "Loneliness-Protective       0.50      0.57      0.53         7\n",
      "               NoSDoH       0.86      0.80      0.83       144\n",
      "\n",
      "            micro avg       0.60      0.69      0.65       271\n",
      "            macro avg       0.25      0.45      0.29       271\n",
      "         weighted avg       0.64      0.69      0.65       271\n",
      "          samples avg       0.68      0.71      0.69       271\n",
      "\n",
      "\n",
      "Saved evaluation results to: ../results/eval/few_shot_eval_30_06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['Digital-NoSDoH', 'Employment-NoSDoH', 'EnglishProficiency-Adverse', 'EnglishProficiency-NoSDoH', 'Finances-NoSDoH', 'FoodAccess-Adverse', 'FoodAccess-NoSDoH', 'FoodAccess-Protective', 'Housing-NoSDoH', 'Loneliness-NoSDoH'] will be ignored\n",
      "  warnings.warn(\n",
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# === Step 2: Run model inference using extractor ===\n",
    "y_true = []\n",
    "y_pred = []\n",
    "sentences = []\n",
    "\n",
    "for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    sentence = row[\"Sentence\"]\n",
    "    gold = sorted(row[\"label_pair\"])\n",
    "    \n",
    "    result = extractor.extract_from_sentence(sentence)\n",
    "    pred = sorted(result[\"sdoh_factors\"])  # list of predicted labels\n",
    "    \n",
    "    y_true.append(gold)\n",
    "    y_pred.append(pred)\n",
    "    sentences.append(sentence)\n",
    "\n",
    "# === Step 3: Binarize for multilabel metrics ===\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_true_bin = mlb.fit_transform(y_true)\n",
    "y_pred_bin = mlb.transform(y_pred)  # must not refit — only transform\n",
    "\n",
    "# === Step 4: Print F1 scores ===\n",
    "print(\"Few-Shot Classification Report:\\n\")\n",
    "print(classification_report(y_true_bin, y_pred_bin, target_names=mlb.classes_))\n",
    "\n",
    "# === Step 5: Save CSV for manual inspection ===\n",
    "eval_results_df = pd.DataFrame({\n",
    "    \"Sentence\": sentences,\n",
    "    \"Gold Labels\": [\", \".join(lbls) for lbls in y_true],\n",
    "    \"Predicted Labels\": [\", \".join(lbls) for lbls in y_pred],\n",
    "    \"Exact Match\": [set(t) == set(p) for t, p in zip(y_true, y_pred)]\n",
    "})\n",
    "\n",
    "eval_results_df.to_csv(\"../results/eval/few_shot_eval_30_06.csv\", index=False)\n",
    "print(\"\\nSaved evaluation results to: ../results/eval/few_shot_eval_30_06.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bc1eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved classification report to: ../results/eval/few_shot_eval_report_30_06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Generate report as dict\n",
    "report_dict = classification_report(\n",
    "    y_true_bin,\n",
    "    y_pred_bin,\n",
    "    target_names=mlb.classes_,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Save to CSV\n",
    "report_path = \"../results/eval/few_shot_eval_report_30_06.csv\"\n",
    "report_df.to_csv(report_path)\n",
    "print(f\"\\nSaved classification report to: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa423439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94eb3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f511d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf75218a",
   "metadata": {},
   "source": [
    "The following script processes a batch of notes, based on the SDoH extractor used for a single note earlier. It includes many options that can be modified:\n",
    "\n",
    "- model name\n",
    "- prompt type\n",
    "- level of classification (1 for mention of SDoH, 2 for adverse vs. protective mention)\n",
    "- batch size and start index\n",
    "\n",
    "\n",
    "To run it, enter the following command in the terminal, after activating the conda environment and adjusting the options:\n",
    "\n",
    "```console\n",
    "python scripts/batch_process_notes.py --model_name \"meta-llama/Llama-3.1-8B-Instruct\" \\\n",
    "                                 --prompt_type \"five_shot_basic\" \\\n",
    "                                 --batch_size 10 \\\n",
    "                                 --start_index 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449f035",
   "metadata": {},
   "source": [
    "We can also evaluate models on the annotation dataset, this is done using another script:\n",
    "\n",
    "```console\n",
    "python scripts/evaluate_on_annotations.py --model_name \"meta-llama/Llama-3.1-8B-Instruct\" \\\n",
    "                                  --prompt_type \"five_shot_basic\" \\\n",
    "                                  --annotation_data \"data/raw/BRC-Data/annotated_BRC_referrals.csv\" \\\n",
    "                                  --sample_size 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de13e5",
   "metadata": {},
   "source": [
    "The evaluation system has two main components:\n",
    "\n",
    "- **Main evaluation script** (`evaluate_on_annotations.py`) -- This is the orchestrator that runs everything;\n",
    "- **Supporting utilies** (`utils/evaluation_helpers_lvl1.py`)-- These handle the specific tasks like model loading, SDoH extraction, and metric calculation.\n",
    "\n",
    "The evaluation script does the following for each sentence:\n",
    "\n",
    "1. **Extract**: Run the sentence through the SDoHExtractor\n",
    "2. **Format**: Convert the model's list output to a comparable string\n",
    "3. **Record**: Store both human and model labels plus metadata\n",
    "4. **Structure**: Build a DataFrame ready for multi-label metrics calculation\n",
    "\n",
    "Demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample annotated data:\n",
      "                                            Sentence  \\\n",
      "0  She needs help with food , toiletry and some cash   \n",
      "1  Mr PERSON was having support of a friend who h...   \n",
      "2  Isolated , housing concern impacting MH SU pre...   \n",
      "3      Equipment delivery to ensure safer discharge.   \n",
      "4  XXXX shopping FBG Patient is no longer driving...   \n",
      "\n",
      "                                Label  \n",
      "0  FoodInsecurity, FinancialSituation  \n",
      "1                       SocialSupport  \n",
      "2              SocialSupport, Housing  \n",
      "3                              NoSDoH  \n",
      "4                      Transportation  \n",
      "Loading meta-llama/Llama-3.1-8B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede2ba6f86824ece9215f51f8bd1d233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ meta-llama/Llama-3.1-8B-Instruct loaded successfully!\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 1 ---\n",
      "Text: She needs help with food , toiletry and some cash...\n",
      "Human labeled: FoodInsecurity, FinancialSituation\n",
      "Model predicted: FinancialSituation, FoodInsecurity\n",
      "Raw model response: <LIST>FinancialSituation, FoodInsecurity</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 2 ---\n",
      "Text: Mr PERSON was having support of a friend who had a car accid...\n",
      "Human labeled: SocialSupport\n",
      "Model predicted: SocialSupport, Transportation\n",
      "Raw model response: <LIST>SocialSupport, Transportation</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 3 ---\n",
      "Text: Isolated , housing concern impacting MH SU previously suppor...\n",
      "Human labeled: SocialSupport, Housing\n",
      "Model predicted: Housing, SocialSupport, SubstanceUse\n",
      "Raw model response: <LIST>Housing, SocialSupport, SubstanceUse</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 4 ---\n",
      "Text: Equipment delivery to ensure safer discharge....\n",
      "Human labeled: NoSDoH\n",
      "Model predicted: NoSDoH\n",
      "Raw model response: <LIST>NoSDoH</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n",
      "\n",
      "--- Sentence 5 ---\n",
      "Text: XXXX shopping FBG Patient is no longer driving , therefore n...\n",
      "Human labeled: Transportation\n",
      "Model predicted: FinancialSituation, SocialSupport, Transportation\n",
      "Raw model response: <LIST>Transportation, FinancialSituation, SocialSupport</LIST>\n",
      "\n",
      "Results DataFrame:\n",
      "                       original_label  \\\n",
      "0  FoodInsecurity, FinancialSituation   \n",
      "1                       SocialSupport   \n",
      "2              SocialSupport, Housing   \n",
      "3                              NoSDoH   \n",
      "4                      Transportation   \n",
      "\n",
      "                                    model_prediction  model_has_sdoh  \n",
      "0                 FinancialSituation, FoodInsecurity            True  \n",
      "1                      SocialSupport, Transportation            True  \n",
      "2               Housing, SocialSupport, SubstanceUse            True  \n",
      "3                                             NoSDoH           False  \n",
      "4  FinancialSituation, SocialSupport, Transportation            True  \n"
     ]
    }
   ],
   "source": [
    "from utils.SDoH_classification_helpers import SDoHExtractor\n",
    "from utils.model_helpers import load_instruction_model\n",
    "\n",
    "# Load annotated data (first few rows for demo)\n",
    "annotated_df = pd.read_csv(\"../data/raw/BRC-Data/annotated_BRC_referrals.csv\")\n",
    "sample_df = annotated_df.head(5)  # Just 5 sentences for demo\n",
    "sample_df.columns = ['CAS', 'Sentence', 'Label', 'Adverse', 'Comments']  # Standardise column names\n",
    "\n",
    "print(\"Sample annotated data:\")\n",
    "print(sample_df[['Sentence', 'Label']])\n",
    "\n",
    "# Load model\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer, model = load_instruction_model(model_name)\n",
    "\n",
    "# Create extractor\n",
    "extractor = SDoHExtractor(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt_type=\"five_shot_basic\",\n",
    "    level=1,\n",
    "    debug=True \n",
    ")\n",
    "\n",
    "# Process each sentence and build results\n",
    "results = []\n",
    "for idx, row in sample_df.iterrows():\n",
    "    sentence = str(row['Sentence']).strip()\n",
    "    \n",
    "    # Extract SDoH from sentence\n",
    "    extraction_result = extractor.extract_from_sentence(sentence)\n",
    "    factors = extraction_result[\"sdoh_factors\"]\n",
    "    \n",
    "    # Convert to comparison format\n",
    "    model_prediction = \", \".join(sorted(factors)) if factors and factors != [\"NoSDoH\"] else \"NoSDoH\"\n",
    "    \n",
    "    # Create result record (same structure as your evaluation script)\n",
    "    result = {\n",
    "        'cas': row['CAS'],\n",
    "        'sentence_number': idx + 1,\n",
    "        'original_sentence': sentence,\n",
    "        'original_label': row['Label'],\n",
    "        'model_prediction': model_prediction,\n",
    "        'model_factors_list': factors,\n",
    "        'model_has_sdoh': factors != [\"NoSDoH\"] and bool(factors),\n",
    "        'num_model_factors': len(factors) if factors != [\"NoSDoH\"] else 0,\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    # Show what happened\n",
    "    print(f\"\\n--- Sentence {idx + 1} ---\")\n",
    "    print(f\"Text: {sentence[:60]}...\")\n",
    "    print(f\"Human labeled: {row['Label']}\")\n",
    "    print(f\"Model predicted: {model_prediction}\")\n",
    "    if extraction_result.get(\"debug\"):\n",
    "        print(f\"Raw model response: {extraction_result['debug']['raw_response']}\")\n",
    "\n",
    "# Convert to DataFrame (ready for metrics calculation)\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd85d2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cas",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "original_sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_prediction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_factors_list",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "model_has_sdoh",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "num_model_factors",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ef20ed23-0a11-4d71-ad1a-c2d11e261e6c",
       "rows": [
        [
         "0",
         "CAS-548353",
         "1",
         "She needs help with food , toiletry and some cash",
         "FoodInsecurity, FinancialSituation",
         "FinancialSituation, FoodInsecurity",
         "['FinancialSituation', 'FoodInsecurity']",
         "True",
         "2"
        ],
        [
         "1",
         "CAS-548411",
         "2",
         "Mr PERSON was having support of a friend who had a car accident , he supported Mr PERSON with food shopping",
         "SocialSupport",
         "SocialSupport, Transportation",
         "['SocialSupport', 'Transportation']",
         "True",
         "2"
        ],
        [
         "2",
         "CAS-548427",
         "3",
         "Isolated , housing concern impacting MH SU previously supported by the SP service",
         "SocialSupport, Housing",
         "Housing, SocialSupport, SubstanceUse",
         "['Housing', 'SocialSupport', 'SubstanceUse']",
         "True",
         "3"
        ],
        [
         "3",
         "CAS-548530",
         "4",
         "Equipment delivery to ensure safer discharge.",
         "NoSDoH",
         "NoSDoH",
         "['NoSDoH']",
         "False",
         "0"
        ],
        [
         "4",
         "CAS-548590",
         "5",
         "XXXX shopping FBG Patient is no longer driving , therefore needs an MP to take him shopping and to the bank to access his money",
         "Transportation",
         "FinancialSituation, SocialSupport, Transportation",
         "['Transportation', 'FinancialSituation', 'SocialSupport']",
         "True",
         "3"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cas</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>original_label</th>\n",
       "      <th>model_prediction</th>\n",
       "      <th>model_factors_list</th>\n",
       "      <th>model_has_sdoh</th>\n",
       "      <th>num_model_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAS-548353</td>\n",
       "      <td>1</td>\n",
       "      <td>She needs help with food , toiletry and some cash</td>\n",
       "      <td>FoodInsecurity, FinancialSituation</td>\n",
       "      <td>FinancialSituation, FoodInsecurity</td>\n",
       "      <td>[FinancialSituation, FoodInsecurity]</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAS-548411</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr PERSON was having support of a friend who h...</td>\n",
       "      <td>SocialSupport</td>\n",
       "      <td>SocialSupport, Transportation</td>\n",
       "      <td>[SocialSupport, Transportation]</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAS-548427</td>\n",
       "      <td>3</td>\n",
       "      <td>Isolated , housing concern impacting MH SU pre...</td>\n",
       "      <td>SocialSupport, Housing</td>\n",
       "      <td>Housing, SocialSupport, SubstanceUse</td>\n",
       "      <td>[Housing, SocialSupport, SubstanceUse]</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAS-548530</td>\n",
       "      <td>4</td>\n",
       "      <td>Equipment delivery to ensure safer discharge.</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>[NoSDoH]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAS-548590</td>\n",
       "      <td>5</td>\n",
       "      <td>XXXX shopping FBG Patient is no longer driving...</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>FinancialSituation, SocialSupport, Transportation</td>\n",
       "      <td>[Transportation, FinancialSituation, SocialSup...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cas  sentence_number  \\\n",
       "0  CAS-548353                1   \n",
       "1  CAS-548411                2   \n",
       "2  CAS-548427                3   \n",
       "3  CAS-548530                4   \n",
       "4  CAS-548590                5   \n",
       "\n",
       "                                   original_sentence  \\\n",
       "0  She needs help with food , toiletry and some cash   \n",
       "1  Mr PERSON was having support of a friend who h...   \n",
       "2  Isolated , housing concern impacting MH SU pre...   \n",
       "3      Equipment delivery to ensure safer discharge.   \n",
       "4  XXXX shopping FBG Patient is no longer driving...   \n",
       "\n",
       "                       original_label  \\\n",
       "0  FoodInsecurity, FinancialSituation   \n",
       "1                       SocialSupport   \n",
       "2              SocialSupport, Housing   \n",
       "3                              NoSDoH   \n",
       "4                      Transportation   \n",
       "\n",
       "                                    model_prediction  \\\n",
       "0                 FinancialSituation, FoodInsecurity   \n",
       "1                      SocialSupport, Transportation   \n",
       "2               Housing, SocialSupport, SubstanceUse   \n",
       "3                                             NoSDoH   \n",
       "4  FinancialSituation, SocialSupport, Transportation   \n",
       "\n",
       "                                  model_factors_list  model_has_sdoh  \\\n",
       "0               [FinancialSituation, FoodInsecurity]            True   \n",
       "1                    [SocialSupport, Transportation]            True   \n",
       "2             [Housing, SocialSupport, SubstanceUse]            True   \n",
       "3                                           [NoSDoH]           False   \n",
       "4  [Transportation, FinancialSituation, SocialSup...            True   \n",
       "\n",
       "   num_model_factors  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  3  \n",
       "3                  0  \n",
       "4                  3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bf239",
   "metadata": {},
   "source": [
    "After classifying SDoH from annotated sentences, the `calculate_multilabel_metrics` function from `utils/evaluation_helpers.py` does three main steps:\n",
    "\n",
    "1. Label parsing & preparation\n",
    "2. Binary matrix conversion\n",
    "\n",
    "    Example: If the labels are [\"Housing\", \"Employment\", \"Social Support\"]:\n",
    "    - [\"Housing\", \"Employment\"] becomes [1, 1, 0]\n",
    "    - [\"Housing\"] becomes [1, 0, 0]\n",
    "    - [\"NoSDoH\"] becomes [0, 0, 0]\n",
    "\n",
    "3. Return multi-Label metrics\n",
    "\n",
    "    The function calculates four types of metrics:\n",
    "    - Example-based: How well does the model predict the exact set of labels for each sentence?\n",
    "    - Label-based: How well does the model perform on each individual label?\n",
    "    - Per-label: Performance breakdown for each SDoH factor\n",
    "    - Statistics: Overall dataset characteristics\n",
    "\n",
    "I can now dive deeper into the metrics used for multi-label classification.\n",
    "\n",
    "1. **Example-Based Metrics (averaged across sentences)**. These look at how well the model predicts the complete set of labels for each sentence:\n",
    "\n",
    "    - Exact Match Ratio (Subset Accuracy): Percentage where model prediction exactly matches human annotation. [\"Housing\", \"Employment\"] == [\"Housing\", \"Employment\"] ✓ = 1.0; [\"Housing\"] vs [\"Housing\", \"Employment\"] ✗ = 0.0\n",
    "    - Hamming Loss: Fraction of wrong label assignments (lower is better). Counts individual label mistakes across all positions; If you have 3 possible labels and get 1 wrong: hamming_loss = 1/3 = 0.33.\n",
    "    - Additional metrics: Example-based Precision/Recall/F1; Jaccard Index\n",
    "2. **Label-Based Metrics (averaged across labels)**. These treat each SDoH factor as a separate binary classification problem:\n",
    "\n",
    "    - Macro-averaged (treats all labels equally). Calculate precision/recall/F1 for each label separately; and average them (rare labels get same weight as common ones)\n",
    "    - Micro-averaged (weighted by frequency). Pool all true/false positives across labels; more influenced by common labels.\n",
    "\n",
    "3. **Per-Label Performance**. Individual precision/recall/F1 for each SDoH factor:\n",
    "4. **Dataset Statistics**\n",
    "\n",
    "    - Label Cardinality: Average number of labels per sentence\n",
    "    - Label Density: Cardinality divided by total possible labels\n",
    "    - Coverage: How many different labels appear at least once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e92f9f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
