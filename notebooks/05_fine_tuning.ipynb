{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf71bef3",
   "metadata": {},
   "source": [
    "# Fine-tuning a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5868cba8",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ef4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729461b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7a67b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,1,2,3\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "print(os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa6993",
   "metadata": {},
   "source": [
    "## 1. Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf70e3d",
   "metadata": {},
   "source": [
    "## 2. Finetuning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15996ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57058a81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf027c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1a759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febda91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd29557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bba9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import (\n",
    "#     AutoTokenizer,\n",
    "#     AutoModelForCausalLM,\n",
    "#     TrainingArguments,\n",
    "#     Trainer,\n",
    "#     DataCollatorForSeq2Seq\n",
    "# )\n",
    "# from peft import get_peft_model, LoraConfig, TaskType\n",
    "# import pandas as pd\n",
    "# from datasets import Dataset\n",
    "\n",
    "# from utils.prompt_creation_helpers import create_guevara_prompt  # helper\n",
    "# from transformers import logging as hf_logging\n",
    "\n",
    "# hf_logging.set_verbosity_info()\n",
    "\n",
    "# # === Configuration ===\n",
    "# MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# CACHE_DIR = \"/data/resource/huggingface/hub\"\n",
    "# CSV_PATH = \"../data/raw/Annotated-MIMIC-III-Data/ManuallyAnnotatedSyntheticSentences.csv\"\n",
    "# OUTPUT_DIR = \"./outputs/llama3_lora_guevara\"\n",
    "\n",
    "# # === Load tokenizer & model (full precision, no quantization) ===\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=CACHE_DIR)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     cache_dir=CACHE_DIR,\n",
    "#     torch_dtype=torch.float16,\n",
    "#    device_map=\"auto\"\n",
    "# )\n",
    "\n",
    "# # === Add LoRA ===\n",
    "# lora_config = LoraConfig(\n",
    "#     r=8,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.CAUSAL_LM\n",
    "# )\n",
    "# model = get_peft_model(model, lora_config)\n",
    "\n",
    "# # === Load and prepare dataset ===\n",
    "# df = pd.read_csv(CSV_PATH)\n",
    "# df = df.dropna(subset=[\"sentence\", \"label\"])  # Ensure clean input\n",
    "# dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# def tokenize(example):\n",
    "#     prompt = create_guevara_prompt(example[\"sentence\"], tokenizer)\n",
    "#     model_inputs = tokenizer(prompt, truncation=True, padding=\"max_length\", max_length=512)\n",
    "#     labels = tokenizer(example[\"label\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "# tokenized_dataset = dataset.map(tokenize)\n",
    "\n",
    "# # === Training Arguments ===\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=OUTPUT_DIR,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     num_train_epochs=3,\n",
    "#     fp16=True,                \n",
    "#     save_total_limit=2,\n",
    "#     logging_steps=10,\n",
    "#     save_steps=200,\n",
    "#     report_to=\"none\"\n",
    "# )\n",
    "\n",
    "# # === Trainer ===\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "# )\n",
    "\n",
    "# # === Train ===\n",
    "# trainer.train()\n",
    "\n",
    "# # === Save the LoRA adapter ===\n",
    "# model.save_pretrained(f\"{OUTPUT_DIR}/lora_adapter_only\")\n",
    "# tokenizer.save_pretrained(f\"{OUTPUT_DIR}/tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
