{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ceccc6",
   "metadata": {},
   "source": [
    "# Miscellaneous code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850d24f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7730f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672a4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae47dd1",
   "metadata": {},
   "source": [
    "## Aesthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colour palette\n",
    "# From https://brand.ifrc.org/ifrc-brand-system/basics/colour\n",
    "colour_palette = {\n",
    "    'ifrc_red': '#EE2435',\n",
    "    'ifrc_darkblue': '#011E41',\n",
    "    'dark_green': '#009775',\n",
    "    'medium_green': '#00AB84',\n",
    "    'light_green': '#47D7AC',\n",
    "    'medium_blue': '#8DCDE2',\n",
    "    'light_blue': '#CCf5FC',\n",
    "    'medium_orange': '#FF8200',\n",
    "    'light_orange': '#FFB25B',\n",
    "    'medium_purple': '#512D6D',\n",
    "    'light_purple': '#958DBE',\n",
    "    'grey': '#A7A8AA',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b6bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cached models:\n",
      "  CohereForAI/aya-23-35B\n",
      "  CohereForAI/aya-23-8B\n",
      "  CohereForAI/aya-vision-8b\n",
      "  HuggingFaceTB/SmolLM-135M-Instruct\n",
      "  LLaMAX/LLaMAX3-8B-Alpaca\n",
      "  Qwen/Qwen1.5-4B\n",
      "  Qwen/Qwen2-7B\n",
      "  Qwen/Qwen2.5-1.5B\n",
      "  Qwen/Qwen2.5-3B\n",
      "  Qwen/Qwen2.5-72B-Instruct\n",
      "  Qwen/Qwen2.5-7B\n",
      "  Qwen/Qwen2.5-7B-Instruct\n",
      "  Qwen/Qwen2.5-7B-instruct\n",
      "  Qwen/Qwen2.5-VL-7B-Instruct\n",
      "  Qwen/Qwen3-0.6B\n",
      "  Qwen/Qwen3-8B\n",
      "  Unbabel/wmt20-comet-qe-da\n",
      "  Unbabel/wmt22-comet-da\n",
      "  bert-base-uncased\n",
      "  bert-large-uncased\n",
      "  cardiffnlp/twitter-roberta-base-sentiment\n",
      "  cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "  clairebarale/refugee_cases_ner\n",
      "  cross-encoder/nli-deberta-v3-large\n",
      "  cross-encoder/stsb-roberta-base\n",
      "  cross-encoder/stsb-roberta-large\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n",
      "  facebook/nllb-200-3.3B\n",
      "  facebook/nllb-200-distilled-1.3B\n",
      "  facebook/nllb-200-distilled-600M\n",
      "  google/gemma-3-1b-it\n",
      "  google/gemma-3-27b-it\n",
      "  google/gemma-3-27b-it-qat-q4_0-gguf\n",
      "  gpt2\n",
      "  gpt2-medium\n",
      "  gpt2-xl\n",
      "  hfl/chinese-bert-wwm\n",
      "  hfl/chinese-electra-180g-small-discriminator\n",
      "  hfl/chinese-legal-electra-base-discriminator\n",
      "  hfl/chinese-legal-electra-small-discriminator\n",
      "  hfl/chinese-roberta-wwm-ext\n",
      "  hfl/chinese-roberta-wwm-ext-large\n",
      "  jxm/gtr__nq__32\n",
      "  jxm/gtr__nq__32__correct\n",
      "  meta-llama/Llama-2-7b-chat-hf\n",
      "  meta-llama/Llama-2-7b-hf\n",
      "  meta-llama/Llama-3.1-70B-Instruct\n",
      "  meta-llama/Llama-3.1-8B\n",
      "  meta-llama/Llama-3.1-8B-Instruct\n",
      "  meta-llama/Llama-3.2-11B-Vision-Instruct\n",
      "  meta-llama/Llama-3.3-70B-Instruct\n",
      "  meta-llama/Llama-4-Scout-17B-16E\n",
      "  meta-llama/Meta-Llama-3-70B-Instruct\n",
      "  meta-llama/Meta-Llama-3-8B\n",
      "  meta-llama/Meta-Llama-3-8B-Instruct\n",
      "  meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "  microsoft/Phi-3-mini-4k-instruct\n",
      "  microsoft/Phi-3.5-vision-instruct\n",
      "  microsoft/Phi-4-mini-instruct\n",
      "  microsoft/Phi-4-multimodal-instruct\n",
      "  microsoft/deberta-large-mnli\n",
      "  microsoft/deberta-v3-base\n",
      "  microsoft/deberta-xlarge\n",
      "  microsoft/deberta-xlarge-mnli\n",
      "  mistral-community/pixtral-12b\n",
      "  mistralai/Mistral-7B-Instruct-v0.2\n",
      "  mistralai/Mistral-7B-Instruct-v0.3\n",
      "  mistralai/Mistral-7B-v0.1\n",
      "  mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "  mosaicml/mpt-7b-chat\n",
      "  nlpaueb/legal-bert-base-uncased\n",
      "  nvidia/Llama-3.1-Nemotron-Nano-8B-v1\n",
      "  openai-community/gpt2\n",
      "  openai-community/gpt2-large\n",
      "  openai-community/gpt2-medium\n",
      "  openai-community/gpt2-xl\n",
      "  openai/whisper-large-v3-turbo\n",
      "  openbmb/MiniCPM-o-2_6\n",
      "  roberta-base\n",
      "  roberta-large\n",
      "  saibo/legal-roberta-base\n",
      "  sentence-transformers/LaBSE\n",
      "  sentence-transformers/all-MPNet-base-v2\n",
      "  sentence-transformers/all-MiniLM-L6-v2\n",
      "  sentence-transformers/all-mpnet-base-v2\n",
      "  sentence-transformers/gtr-t5-base\n",
      "  sentence-transformers/msmarco-bert-co-condensor\n",
      "  sentence-transformers/paraphrase-distilroberta-base-v2\n",
      "  sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "  sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
      "  shibing624/text2vec-base-chinese\n",
      "  t5-base\n",
      "  t5-large\n",
      "  t5-small\n",
      "  unsloth/llama-3-8b-bnb-4bit\n",
      "  unsloth/meta-llama-3.1-8b-instruct-bnb-4bit\n",
      "  unslothai/2\n",
      "  unslothai/4\n",
      "  unslothai/other\n",
      "  unslothai/repeat\n",
      "  unslothai/vram-48\n",
      "  vahidthegreat/StanceAware-SBERT\n",
      "  xlm-roberta-base\n",
      "  xlm-roberta-large\n"
     ]
    }
   ],
   "source": [
    "# Check models\n",
    "# What models are available\n",
    "cache_dir = \"/data/resource/huggingface/hub\"\n",
    "available_models = []\n",
    "\n",
    "if os.path.exists(cache_dir):\n",
    "    for item in os.listdir(cache_dir):\n",
    "        if item.startswith(\"models--\"):\n",
    "            # Convert models--org--name to org/name format\n",
    "            model_name = item.replace(\"models--\", \"\").replace(\"--\", \"/\")\n",
    "            available_models.append(model_name)\n",
    "\n",
    "print(\"Available cached models:\")\n",
    "for model in sorted(available_models):\n",
    "    print(f\"  {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e5ab86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  4 CUDA device(s) detected:\n",
      "\n",
      "Device 0: NVIDIA L40S\n",
      "Device 1: NVIDIA L40S\n",
      "Device 2: NVIDIA A100 80GB PCIe\n",
      "Device 3: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"ðŸ§  {torch.cuda.device_count()} CUDA device(s) detected:\\n\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1e087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.llama.multi_label_full.prepare_dataset import prepare_multilabel_dataset\n",
    "from scripts.llama.multi_label_full.prepare_dataset import prepare_multilabel_dataset_infer\n",
    "\n",
    "val_prepared = prepare_multilabel_dataset(\"../data/processed/train-test/val_set.csv\")\n",
    "val_prepared_df = val_prepared.to_pandas()\n",
    "\n",
    "test_prepared_df = prepare_multilabel_dataset_infer(\"../data/processed/train-test/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3980a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.llama.multi_label_full_adverse.prepare_dataset import prepare_adverse_only_dataset, prepare_adverse_only_dataset_infer\n",
    "\n",
    "val_prepared_adverse = prepare_adverse_only_dataset(\"../data/processed/train-test/val_set.csv\")\n",
    "val_prepared_adverse_df = val_prepared_adverse.to_pandas()\n",
    "\n",
    "test_prepared_adverse_df = prepare_adverse_only_dataset_infer(\"../data/processed/train-test/test_set.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea6406f",
   "metadata": {},
   "source": [
    "## Two-step pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b43e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.multistep.two_step_pipeline import run_two_step_pipeline\n",
    "\n",
    "run_two_step_pipeline(\n",
    "        test_data_file=\"../data/processed/train-test/test_set.csv\",\n",
    "        roberta_model_dir=\"../results/model_training/roberta_binary_sdoh/roberta-base_bs16_lr9e-05_20250709_170452/checkpoint-24\",\n",
    "        llama_model_dir=\"../results/model_training/llama_lora_multi_label_full/Llama-3.1-8B-Instruct_bs8_lr9e-05_epochs6_20250710_164937\",\n",
    "        pos_weight=1.5251,\n",
    "        output_file=\"../results/multistep/two_step_predictions.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea40ae",
   "metadata": {},
   "source": [
    "### Step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9187313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_pair",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label_string",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "completion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "binary_label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "399af853-939a-487b-9f76-c92b9ac2865a",
       "rows": [
        [
         "0",
         "She is able to sit out for XXXX hours between care calls .",
         "['NoSDoH']",
         "NoSDoH",
         "<LIST>NoSDoH</LIST>",
         "0"
        ],
        [
         "1",
         "He is currently treated with Sinemet and Ropinirole .",
         "['NoSDoH']",
         "NoSDoH",
         "<LIST>NoSDoH</LIST>",
         "0"
        ],
        [
         "2",
         "Marker on Essex Wellbeing Record that she was aggressive / violent towards Community Agents .",
         "['NoSDoH']",
         "NoSDoH",
         "<LIST>NoSDoH</LIST>",
         "0"
        ],
        [
         "3",
         "She needs help with food , toiletry and some cash .",
         "['Finances-Adverse', 'FoodAccess-Adverse']",
         "Finances-Adverse|FoodAccess-Adverse",
         "<LIST>Finances-Adverse, FoodAccess-Adverse</LIST>",
         "1"
        ],
        [
         "4",
         "support to find a cleaning service in community + welfare checks",
         "['Housing-Adverse']",
         "Housing-Adverse",
         "<LIST>Housing-Adverse</LIST>",
         "1"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>label_pair</th>\n",
       "      <th>label_string</th>\n",
       "      <th>completion</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She is able to sit out for XXXX hours between ...</td>\n",
       "      <td>['NoSDoH']</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is currently treated with Sinemet and Ropin...</td>\n",
       "      <td>['NoSDoH']</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marker on Essex Wellbeing Record that she was ...</td>\n",
       "      <td>['NoSDoH']</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She needs help with food , toiletry and some c...</td>\n",
       "      <td>['Finances-Adverse', 'FoodAccess-Adverse']</td>\n",
       "      <td>Finances-Adverse|FoodAccess-Adverse</td>\n",
       "      <td>&lt;LIST&gt;Finances-Adverse, FoodAccess-Adverse&lt;/LIST&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>support to find a cleaning service in communit...</td>\n",
       "      <td>['Housing-Adverse']</td>\n",
       "      <td>Housing-Adverse</td>\n",
       "      <td>&lt;LIST&gt;Housing-Adverse&lt;/LIST&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  She is able to sit out for XXXX hours between ...   \n",
       "1  He is currently treated with Sinemet and Ropin...   \n",
       "2  Marker on Essex Wellbeing Record that she was ...   \n",
       "3  She needs help with food , toiletry and some c...   \n",
       "4  support to find a cleaning service in communit...   \n",
       "\n",
       "                                   label_pair  \\\n",
       "0                                  ['NoSDoH']   \n",
       "1                                  ['NoSDoH']   \n",
       "2                                  ['NoSDoH']   \n",
       "3  ['Finances-Adverse', 'FoodAccess-Adverse']   \n",
       "4                         ['Housing-Adverse']   \n",
       "\n",
       "                          label_string  \\\n",
       "0                               NoSDoH   \n",
       "1                               NoSDoH   \n",
       "2                               NoSDoH   \n",
       "3  Finances-Adverse|FoodAccess-Adverse   \n",
       "4                      Housing-Adverse   \n",
       "\n",
       "                                          completion  binary_label  \n",
       "0                                <LIST>NoSDoH</LIST>             0  \n",
       "1                                <LIST>NoSDoH</LIST>             0  \n",
       "2                                <LIST>NoSDoH</LIST>             0  \n",
       "3  <LIST>Finances-Adverse, FoodAccess-Adverse</LIST>             1  \n",
       "4                       <LIST>Housing-Adverse</LIST>             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Setup + Read Data\n",
    "import os\n",
    "import pandas as pd\n",
    "from scripts.roberta.dataset import is_sdoh_label\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "\n",
    "test_path = \"../data/processed/train-test/test_set.csv\"\n",
    "roberta_model_dir = \"../results/model_training/roberta_binary_sdoh/roberta-base_bs16_lr9e-05_20250709_170452/checkpoint-24\"\n",
    "llama_model_dir = \"../results/model_training/llama_lora_multi_label_full/Llama-3.1-8B-Instruct_bs8_lr9e-05_epochs6_20250710_164937\"\n",
    "pos_weight = 1.5251\n",
    "\n",
    "df = pd.read_csv(test_path)\n",
    "df[\"binary_label\"] = df[\"completion\"].apply(is_sdoh_label)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59cbc7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1548339/3982882224.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP 2: Load RoBERTa and Predict\n",
    "from transformers import RobertaTokenizer, RobertaConfig, Trainer\n",
    "from scripts.roberta.dataset import BinarySDoHDataset\n",
    "from scripts.roberta.model import RobertaBinaryClassifierWithWeight\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "config = RobertaConfig.from_pretrained(roberta_model_dir)\n",
    "\n",
    "model = RobertaBinaryClassifierWithWeight.from_pretrained(\n",
    "    roberta_model_dir,\n",
    "    config=config,\n",
    "    pos_weight=pos_weight\n",
    ")\n",
    "\n",
    "dataset = BinarySDoHDataset(df, tokenizer)\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer)\n",
    "outputs = trainer.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "131ed96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "completion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "roberta_pred_sdoh",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "roberta_prob_sdoh",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "f95a2e4d-d278-474b-a3f4-18a34b556102",
       "rows": [
        [
         "0",
         "She is able to sit out for XXXX hours between care calls .",
         "<LIST>NoSDoH</LIST>",
         "0",
         "0.4510482"
        ],
        [
         "1",
         "He is currently treated with Sinemet and Ropinirole .",
         "<LIST>NoSDoH</LIST>",
         "0",
         "0.044357546"
        ],
        [
         "2",
         "Marker on Essex Wellbeing Record that she was aggressive / violent towards Community Agents .",
         "<LIST>NoSDoH</LIST>",
         "1",
         "0.6065941"
        ],
        [
         "3",
         "She needs help with food , toiletry and some cash .",
         "<LIST>Finances-Adverse, FoodAccess-Adverse</LIST>",
         "1",
         "0.9689461"
        ],
        [
         "4",
         "support to find a cleaning service in community + welfare checks",
         "<LIST>Housing-Adverse</LIST>",
         "1",
         "0.9213233"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>completion</th>\n",
       "      <th>roberta_pred_sdoh</th>\n",
       "      <th>roberta_prob_sdoh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She is able to sit out for XXXX hours between ...</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is currently treated with Sinemet and Ropin...</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marker on Essex Wellbeing Record that she was ...</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0.606594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She needs help with food , toiletry and some c...</td>\n",
       "      <td>&lt;LIST&gt;Finances-Adverse, FoodAccess-Adverse&lt;/LIST&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>support to find a cleaning service in communit...</td>\n",
       "      <td>&lt;LIST&gt;Housing-Adverse&lt;/LIST&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0.921323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0  She is able to sit out for XXXX hours between ...   \n",
       "1  He is currently treated with Sinemet and Ropin...   \n",
       "2  Marker on Essex Wellbeing Record that she was ...   \n",
       "3  She needs help with food , toiletry and some c...   \n",
       "4  support to find a cleaning service in communit...   \n",
       "\n",
       "                                          completion  roberta_pred_sdoh  \\\n",
       "0                                <LIST>NoSDoH</LIST>                  0   \n",
       "1                                <LIST>NoSDoH</LIST>                  0   \n",
       "2                                <LIST>NoSDoH</LIST>                  1   \n",
       "3  <LIST>Finances-Adverse, FoodAccess-Adverse</LIST>                  1   \n",
       "4                       <LIST>Housing-Adverse</LIST>                  1   \n",
       "\n",
       "   roberta_prob_sdoh  \n",
       "0           0.451048  \n",
       "1           0.044358  \n",
       "2           0.606594  \n",
       "3           0.968946  \n",
       "4           0.921323  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 3: Add RoBERTa Predictions\n",
    "probs = torch.sigmoid(torch.tensor(outputs.predictions)).numpy().flatten()\n",
    "y_pred = (probs > 0.5).astype(int)\n",
    "\n",
    "df[\"roberta_prob_sdoh\"] = probs\n",
    "df[\"roberta_pred_sdoh\"] = y_pred\n",
    "df_roberta = df[[\"Sentence\", \"completion\", \"roberta_pred_sdoh\", \"roberta_prob_sdoh\"]].copy()\n",
    "df_roberta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7ac79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5: Prepare Subset for LLaMA\n",
    "df_flagged = df_roberta[df_roberta[\"roberta_pred_sdoh\"] == 1].copy()\n",
    "df_flagged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e7f890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1884ceeeab14dc8b3d548ec84efdca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— Loading LoRA adapters from: ../results/model_training/llama_lora_multi_label_full/Llama-3.1-8B-Instruct_bs8_lr9e-05_epochs6_20250710_164937\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Run LLaMA on Flagged Sentences\n",
    "from scripts.llama.shared_utils.model import load_lora_llama\n",
    "from scripts.llama.multi_label_full.prepare_dataset import prepare_multilabel_dataset_infer\n",
    "from tqdm import tqdm\n",
    "\n",
    "model, tokenizer = load_lora_llama(\n",
    "    base_model_path=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    adapter_path=llama_model_dir,\n",
    "    cache_dir=\"/data/resource/huggingface/hub\",\n",
    "    device=0\n",
    ")\n",
    "\n",
    "df_prompted = prepare_multilabel_dataset_infer(df_flagged.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdde4090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113/113 [01:13<00:00,  1.54it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "generated_completion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6160f806-124c-442e-8c59-6996b4acfe8d",
       "rows": [
        [
         "2",
         "Marker on Essex Wellbeing Record that she was aggressive / violent towards Community Agents .",
         "<LIST>NoSDoH</LIST>"
        ],
        [
         "3",
         "She needs help with food , toiletry and some cash .",
         "<LIST>FoodAccess, Finances</LIST>"
        ],
        [
         "4",
         "support to find a cleaning service in community + welfare checks",
         "<LIST>Housing, Loneliness</LIST>"
        ],
        [
         "5",
         "PERSON has hearing aids & struggles with phone calls .",
         "<LIST>NoSDoH</LIST>"
        ],
        [
         "6",
         "The patient requires the internet to complete shopping so may need assistance to complete this whilst awaiting internet to be fixed .",
         "<LIST>DigitalInclusion</LIST>"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>generated_completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marker on Essex Wellbeing Record that she was ...</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She needs help with food , toiletry and some c...</td>\n",
       "      <td>&lt;LIST&gt;FoodAccess, Finances&lt;/LIST&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>support to find a cleaning service in communit...</td>\n",
       "      <td>&lt;LIST&gt;Housing, Loneliness&lt;/LIST&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PERSON has hearing aids &amp; struggles with phone...</td>\n",
       "      <td>&lt;LIST&gt;NoSDoH&lt;/LIST&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The patient requires the internet to complete ...</td>\n",
       "      <td>&lt;LIST&gt;DigitalInclusion&lt;/LIST&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "2  Marker on Essex Wellbeing Record that she was ...   \n",
       "3  She needs help with food , toiletry and some c...   \n",
       "4  support to find a cleaning service in communit...   \n",
       "5  PERSON has hearing aids & struggles with phone...   \n",
       "6  The patient requires the internet to complete ...   \n",
       "\n",
       "                generated_completion  \n",
       "2                <LIST>NoSDoH</LIST>  \n",
       "3  <LIST>FoodAccess, Finances</LIST>  \n",
       "4   <LIST>Housing, Loneliness</LIST>  \n",
       "5                <LIST>NoSDoH</LIST>  \n",
       "6      <LIST>DigitalInclusion</LIST>  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 7: Generate Predictions\n",
    "def extract_list_output(text):\n",
    "    start, end = text.find(\"<LIST>\"), text.find(\"</LIST>\")\n",
    "    return text[start:end+7] if start != -1 and end != -1 else \"NO_LIST_FOUND\"\n",
    "\n",
    "def generate_response(prompt):\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    decoded = tokenizer.decode(output[0][input_len:], skip_special_tokens=True)\n",
    "    return decoded.strip()\n",
    "\n",
    "predictions = []\n",
    "for prompt in tqdm(df_prompted[\"prompt\"]):\n",
    "    output = generate_response(prompt)\n",
    "    predictions.append(extract_list_output(output))\n",
    "\n",
    "df_prompted[\"generated_completion\"] = predictions\n",
    "df_llama = df_prompted[[\"Sentence\", \"generated_completion\"]]\n",
    "df_llama.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Merge and Create Final Predictions\n",
    "df_final = df_roberta.merge(df_llama, on=\"Sentence\", how=\"left\")\n",
    "df_final[\"final_prediction\"] = df_final.apply(\n",
    "    lambda row: row[\"generated_completion\"] if row[\"roberta_pred_sdoh\"] == 1 else \"<LIST>NoSDoH</LIST>\",\n",
    "    axis=1\n",
    ")\n",
    "df_final[[\"Sentence\", \"completion\", \"final_prediction\"]].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
