{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d71a71a",
   "metadata": {},
   "source": [
    "# Few-shot Classifiction of SDoH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f133f46",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51994ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb2a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b75ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SDOH categories\n",
    "EXPECTED_SDOH = [\n",
    "        'EmploymentStatus', 'Housing', 'Transportation', 'ParentalStatus',\n",
    "        'RelationshipStatus', 'SocialSupport', 'SubstanceUse', \n",
    "        'FinancialSituation', 'EducationLevel', 'FoodInsecurity',\n",
    "        'NoSDOH'\n",
    "    ]\n",
    "\n",
    "GUEVARA_SDOH = [\n",
    "    'EMPLOYMENT', 'HOUSING', 'PARENT', 'RELATIONSHIP',\n",
    "    'SUPPORT', 'TRANSPORTATION'\n",
    "]\n",
    "\n",
    "# Load cleaned data\n",
    "brc_referrals_cleaned = pd.read_csv(\"../data/processed/referrals_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c7cf8",
   "metadata": {},
   "source": [
    "## 1. Few-shot classification of SDoH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1461c3e",
   "metadata": {},
   "source": [
    "### 1.1 Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3ed5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available cached models:\n",
      "  CohereForAI/aya-23-35B\n",
      "  CohereForAI/aya-23-8B\n",
      "  CohereForAI/aya-vision-8b\n",
      "  HuggingFaceTB/SmolLM-135M-Instruct\n",
      "  LLaMAX/LLaMAX3-8B-Alpaca\n",
      "  Qwen/Qwen2.5-1.5B\n",
      "  Qwen/Qwen2.5-3B\n",
      "  Qwen/Qwen2.5-72B-Instruct\n",
      "  Qwen/Qwen2.5-7B\n",
      "  Qwen/Qwen2.5-7B-Instruct\n",
      "  Qwen/Qwen2.5-7B-instruct\n",
      "  Qwen/Qwen2.5-VL-7B-Instruct\n",
      "  Qwen/Qwen3-0.6B\n",
      "  Qwen/Qwen3-8B\n",
      "  Unbabel/wmt20-comet-qe-da\n",
      "  Unbabel/wmt22-comet-da\n",
      "  bert-base-uncased\n",
      "  bert-large-uncased\n",
      "  cardiffnlp/twitter-roberta-base-sentiment\n",
      "  clairebarale/refugee_cases_ner\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Llama-70B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\n",
      "  deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\n",
      "  facebook/nllb-200-3.3B\n",
      "  facebook/nllb-200-distilled-1.3B\n",
      "  facebook/nllb-200-distilled-600M\n",
      "  google/gemma-3-1b-it\n",
      "  google/gemma-3-27b-it\n",
      "  google/gemma-3-27b-it-qat-q4_0-gguf\n",
      "  gpt2\n",
      "  gpt2-medium\n",
      "  gpt2-xl\n",
      "  hfl/chinese-bert-wwm\n",
      "  hfl/chinese-electra-180g-small-discriminator\n",
      "  hfl/chinese-legal-electra-base-discriminator\n",
      "  hfl/chinese-legal-electra-small-discriminator\n",
      "  hfl/chinese-roberta-wwm-ext\n",
      "  hfl/chinese-roberta-wwm-ext-large\n",
      "  jxm/gtr__nq__32\n",
      "  jxm/gtr__nq__32__correct\n",
      "  meta-llama/Llama-2-7b-chat-hf\n",
      "  meta-llama/Llama-2-7b-hf\n",
      "  meta-llama/Llama-3.1-70B-Instruct\n",
      "  meta-llama/Llama-3.1-8B\n",
      "  meta-llama/Llama-3.1-8B-Instruct\n",
      "  meta-llama/Llama-3.2-11B-Vision-Instruct\n",
      "  meta-llama/Llama-3.3-70B-Instruct\n",
      "  meta-llama/Llama-4-Scout-17B-16E\n",
      "  meta-llama/Meta-Llama-3-70B-Instruct\n",
      "  meta-llama/Meta-Llama-3-8B\n",
      "  meta-llama/Meta-Llama-3-8B-Instruct\n",
      "  meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "  microsoft/Phi-3-mini-4k-instruct\n",
      "  microsoft/Phi-3.5-vision-instruct\n",
      "  microsoft/Phi-4-mini-instruct\n",
      "  microsoft/Phi-4-multimodal-instruct\n",
      "  microsoft/deberta-large-mnli\n",
      "  microsoft/deberta-v3-base\n",
      "  microsoft/deberta-xlarge\n",
      "  microsoft/deberta-xlarge-mnli\n",
      "  mistral-community/pixtral-12b\n",
      "  mistralai/Mistral-7B-Instruct-v0.2\n",
      "  mistralai/Mistral-7B-Instruct-v0.3\n",
      "  mistralai/Mistral-7B-v0.1\n",
      "  mistralai/Mixtral-8x7B-Instruct-v0.1\n",
      "  mosaicml/mpt-7b-chat\n",
      "  nlpaueb/legal-bert-base-uncased\n",
      "  nvidia/Llama-3.1-Nemotron-Nano-8B-v1\n",
      "  openai-community/gpt2\n",
      "  openai/whisper-large-v3-turbo\n",
      "  openbmb/MiniCPM-o-2_6\n",
      "  roberta-base\n",
      "  roberta-large\n",
      "  saibo/legal-roberta-base\n",
      "  sentence-transformers/LaBSE\n",
      "  sentence-transformers/all-MPNet-base-v2\n",
      "  sentence-transformers/all-MiniLM-L6-v2\n",
      "  sentence-transformers/all-mpnet-base-v2\n",
      "  sentence-transformers/gtr-t5-base\n",
      "  sentence-transformers/msmarco-bert-co-condensor\n",
      "  sentence-transformers/paraphrase-distilroberta-base-v2\n",
      "  sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "  sentence-transformers/paraphrase-multilingual-mpnet-base-v2\n",
      "  shibing624/text2vec-base-chinese\n",
      "  t5-base\n",
      "  t5-large\n",
      "  t5-small\n",
      "  vahidthegreat/StanceAware-SBERT\n",
      "  xlm-roberta-base\n",
      "  xlm-roberta-large\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "# Use shared cache\n",
    "os.environ['HF_HOME'] = '/data/resource/huggingface'\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'  # Force offline mode\n",
    "\n",
    "# What models are available\n",
    "cache_dir = \"/data/resource/huggingface/hub\"\n",
    "available_models = []\n",
    "\n",
    "if os.path.exists(cache_dir):\n",
    "    for item in os.listdir(cache_dir):\n",
    "        if item.startswith(\"models--\"):\n",
    "            # Convert models--org--name to org/name format\n",
    "            model_name = item.replace(\"models--\", \"\").replace(\"--\", \"/\")\n",
    "            available_models.append(model_name)\n",
    "\n",
    "print(\"Available cached models:\")\n",
    "for model in sorted(available_models):\n",
    "    print(f\"  {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c75c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.52.3\n",
      "PyTorch version: 2.6.0\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a6ca370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading meta-llama/Llama-3.1-8B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c655c0fe1c441181efa7979454fa0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ meta-llama/Llama-3.1-8B-Instruct loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load one of the instruction-tuned models\n",
    "# Qwen/Qwen2.5-7B-Instruct\n",
    "# meta-llama/Llama-3.1-8B-Instruct\n",
    "# microsoft/Phi-4-mini-instruct\n",
    "# mistralai/Mistral-7B-Instruct-v0.3\n",
    "\n",
    "from utils.model_helpers import load_instruction_model\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer, model = None, None\n",
    "\n",
    "tokenizer, model = load_instruction_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e423c8c5",
   "metadata": {},
   "source": [
    "### 1.2 Extraction from one note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f573d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a specific note: Case Reference = CAS-467812\n",
    "sample_note = brc_referrals_cleaned[brc_referrals_cleaned['Case Reference'] == 'CAS-467812'].iloc[0]['Referral Notes (depersonalised)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3309a",
   "metadata": {},
   "source": [
    "#### Defining the classification task\n",
    "\n",
    "I define a similar classification task as Guevara et al. (2024). I also added 4 of the 21 SDoH used in Keloth et al. (2025)\n",
    "\n",
    "**Task**: Multi-label sentence-level classification\n",
    "\n",
    "**SDoH**: 10 SDoH categories\n",
    "\n",
    "Guevara et al. (2024) & Keloth et al. (2025):\n",
    "- Employment status \n",
    "- Housing issues \n",
    "- Transportation issues \n",
    "- Parental status\n",
    "- Relationship status\n",
    "- Social support\n",
    "\n",
    "Keloth et al. (2025)\n",
    "- Substance use\n",
    "- Financial issues\n",
    "- Education level \n",
    "- Food insecurity\n",
    "\n",
    "I define two levels of classification, similarly to the papers cited above:\n",
    "\n",
    "1. Level 1: *Any SDoH mentions*. The presence of language describing an SDoH category as defined above, regardless of the attribute. \n",
    "2. Level 2: *Adverse SDoH mentions*. The presence or absence of language describing an SDoH category with an attribute that could create an additional social work or resource support need for patients:\n",
    "    - Employment status: unemployed, underemployed, disability\n",
    "    - Housing issue: financial status, undomiciled, other\n",
    "    - Transportation issue: distance, resources, other\n",
    "    - Parental status: having a child under 18 years old\n",
    "    - Relationship: widowed, divorced, single\n",
    "    - Social support: absence of social support\n",
    "    - Substance use: alcohol abuse, drug use, smoking\n",
    "    - Financial issues: poverty, debt, inability to pay bills, benefit dependency\n",
    "    - Education level: low education, illiteracy, lack of qualifications\n",
    "    - Food insecurity: hunger, inability to afford food, reliance on food banks, poor nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a907ccb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n",
      "==================================================\n",
      "Example Prompt (Five Shot Basic):\n",
      "==================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are analyzing a referral note sentence to identify mentions of Social Determinants of Health (SDoH).\n",
      "\n",
      "Given a sentence, output all SDoH factors that can be inferred from that sentence from the following list: \n",
      "EmploymentStatus, Housing, Transportation, ParentalStatus, RelationshipStatus, SocialSupport, SubstanceUse, FinancialSituation, EducationLevel, FoodInsecurity. \n",
      "\n",
      "If the sentence does NOT mention any of the above categories, output <LIST>NoSDoH</LIST>.\n",
      "\n",
      "Your response must be a comma-separated list of SDoH factors embedded with <LIST> and </LIST>.\n",
      "\n",
      "**STRICT RULES**: \n",
      "- DO NOT generate any other text, explanations, or new SDoH labels.\n",
      "- A sentence CAN be labeled with one or more SDoH factors.\n",
      "- Your response must ONLY contain the <LIST>...</LIST> format.\n",
      "- Do not continue or complete the input sentence.\n",
      "\n",
      "EXAMPLES:\n",
      "Input: \"Person is unemployed and lives with his elderly mother.\"\n",
      "Output: <LIST>EmploymentStatus</LIST>\n",
      "\n",
      "Input: \"She struggles to afford groceries and has no car to get to the store.\"\n",
      "Output: <LIST>FinancialSituation, Transportation, FoodInsecurity</LIST>\n",
      "\n",
      "Input: \"Person smokes cigarettes and drinks alcohol daily.\"\n",
      "Output: <LIST>SubstanceUse</LIST>\n",
      "\n",
      "Input: \"He has three young children at home and receives help from his sister.\"\n",
      "Output: <LIST>ParentalStatus, SocialSupport</LIST>\n",
      "\n",
      "Input: \"Person was prescribed medication for diabetes.\"\n",
      "Output: <LIST>NoSDoH</LIST><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input: \"This is a sentence\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n",
      "==================================================\n",
      "Example Prompt (Five Shot Detailed):\n",
      "==================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are analyzing a referral note sentence to identify mentions of Social Determinants of Health (SDoH).\n",
      "\n",
      "Given a sentence, output all SDoH factors that can be inferred from that sentence from the following list: \n",
      "EmploymentStatus, Housing, Transportation, ParentalStatus, RelationshipStatus, SocialSupport, SubstanceUse, FinancialSituation, EducationLevel, FoodInsecurity. \n",
      "\n",
      "If the sentence does NOT mention any of the above categories, output <LIST>NoSDoH</LIST>.\n",
      "\n",
      "Your response must be a comma-separated list of SDoH factors embedded with <LIST> and </LIST>.\n",
      "\n",
      "**STRICT RULES**: \n",
      "- DO NOT generate any other text, explanations, or new SDoH labels.\n",
      "- A sentence CAN be labeled with one or more SDoH factors.\n",
      "- Your response must ONLY contain the <LIST>...</LIST> format.\n",
      "- Do not continue or complete the input sentence.\n",
      "\n",
      "EXAMPLES:\n",
      "Input: \"Person is unemployed and lives with his elderly mother.\"\n",
      "Output: <LIST>EmploymentStatus</LIST>\n",
      "\n",
      "Input: \"She struggles to afford groceries and has no car to get to the store.\"\n",
      "Output: <LIST>FinancialSituation, Transportation, FoodInsecurity</LIST>\n",
      "\n",
      "Input: \"Person smokes cigarettes and drinks alcohol daily.\"\n",
      "Output: <LIST>SubstanceUse</LIST>\n",
      "\n",
      "Input: \"He has three young children at home and receives help from his sister.\"\n",
      "Output: <LIST>ParentalStatus, SocialSupport</LIST>\n",
      "\n",
      "Input: \"Person was prescribed medication for diabetes.\"\n",
      "Output: <LIST>NoSDoH</LIST><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input: \"This is a sentence\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n",
      "==================================================\n",
      "Example Prompt (Five Shot Basic - Level 2):\n",
      "==================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are analyzing a referral note sentence to identify Social Determinants of Health, and classifying them as Adverse or Protective.\n",
      "\n",
      "Given a sentence, output all SDoH factors that can be inferred from that sentence from the following list: \n",
      "EmploymentStatus, Housing, Transportation, ParentalStatus, RelationshipStatus, SocialSupport, SubstanceUse, FinancialSituation, EducationLevel, FoodInsecurity. \n",
      "\n",
      "If the sentence does NOT mention any of the above categories, output <LIST>NoSDoH</LIST>.\n",
      "\n",
      "Your response must be a comma-separated list of SDoH factors embedded with <LIST> and </LIST>.\n",
      "\n",
      "**STRICT RULES**:\n",
      "- For EVERY SDoH mention found, you MUST classify it as either \"Adverse\" or \"Protective\" after a hyphen\n",
      "- DO NOT generate any other text, explanations, or new SDoH labels.\n",
      "- A sentence CAN be labeled with one or more SDoH factors.\n",
      "- Your response must ONLY contain the <LIST>...</LIST> format.\n",
      "- Do not continue or complete the input sentence.\n",
      "\n",
      "EXAMPLES:\n",
      "Input: \"Person is unemployed and lives with his elderly mother.\"\n",
      "Output: <LIST>EmploymentStatus-Adverse</LIST>\n",
      "\n",
      "Input: \"She struggles to afford groceries and has no car to get to the store.\"\n",
      "Output: <LIST>FinancialSituation-Adverse, Transportation-Adverse, FoodInsecurity-Adverse</LIST>\n",
      "\n",
      "Input: \"Person smokes cigarettes and drinks alcohol daily.\"\n",
      "Output: <LIST>SubstanceUse-Adverse</LIST>\n",
      "\n",
      "Input: \"He has three young children at home and receives help from his sister.\"\n",
      "Output: <LIST>ParentalStatus-Adverse, SocialSupport-Protective</LIST>\n",
      "\n",
      "Input: \"Person was prescribed medication for diabetes.\"\n",
      "Output: <LIST>NoSDoH</LIST><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input: \"This is a sentence\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.prompt_creation_helpers import create_automated_prompt\n",
    "\n",
    "prompt_example_basic = create_automated_prompt(\"This is a sentence\", tokenizer=tokenizer, prompt_type=\"five_shot_basic\", level=1)\n",
    "print(\"=\" * 50)\n",
    "print(\"Example Prompt (Five Shot Basic):\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt_example_basic)\n",
    "\n",
    "prompt_example_detailed = create_automated_prompt(\"This is a sentence\", tokenizer=tokenizer, prompt_type=\"five_shot_basic\", level=1)\n",
    "print(\"=\" * 50)\n",
    "print(\"Example Prompt (Five Shot Detailed):\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt_example_detailed)\n",
    "\n",
    "prompt_example_basic_lvl2 = create_automated_prompt(\"This is a sentence\", tokenizer=tokenizer, prompt_type=\"five_shot_basic\", level=2)\n",
    "print(\"=\" * 50)\n",
    "print(\"Example Prompt (Five Shot Basic - Level 2):\")\n",
    "print(\"=\" * 50)\n",
    "print(prompt_example_basic_lvl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f19121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SDoH_classification_helpers import SDoHExtractor\n",
    "\n",
    "# Initialize the SDoH extractor\n",
    "extractor_lvl1 = SDoHExtractor(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt_type=\"five_shot_detailed\",\n",
    "    level=1,\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "# Extract SDoH factors\n",
    "results_lvl1 = extractor_lvl1.extract_from_note(sample_note)\n",
    "results_lvl1_df = extractor_lvl1.results_to_dataframe(results_lvl1, note_id=\"sample\")\n",
    "\n",
    "print(\"\\nExtracted SDoH Factors (Level 1):\")\n",
    "display(results_lvl1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some debugging\n",
    "print(\"Prompt: \\n\")\n",
    "print(results_lvl1['sentences'][1]['debug']['prompt'])\n",
    "\n",
    "print(\"Raw response: \\n\")\n",
    "print(results_lvl1['sentences'][1]['debug']['raw_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93699669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SDoH extractor (level 2)\n",
    "extractor_lvl2 = SDoHExtractor(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt_type=\"five_shot_basic\",\n",
    "    level=2,\n",
    "    debug=True,\n",
    ")\n",
    "\n",
    "# Extract SDoH factors\n",
    "results_lvl2 = extractor_lvl2.extract_from_note(sample_note)\n",
    "results_lvl2_df = extractor_lvl2.results_to_dataframe(results_lvl2, note_id=\"sample\")\n",
    "\n",
    "print(\"\\nExtracted SDoH Factors (Level 2):\")\n",
    "display(results_lvl2_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016e3df",
   "metadata": {},
   "source": [
    "### 1.3. Extracting from multiple notes (batch processing) and evaluating few-shot extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75218a",
   "metadata": {},
   "source": [
    "The following script processes a batch of notes, based on the SDoH extractor used for a single note earlier. It includes many options that can be modified:\n",
    "\n",
    "- model name\n",
    "- prompt type\n",
    "- level of classification (1 for mention of SDoH, 2 for adverse vs. protective mention)\n",
    "- batch size and start index\n",
    "\n",
    "\n",
    "To run it, enter the following command in the terminal, after activating the conda environment and adjusting the options:\n",
    "\n",
    "```console\n",
    "python scripts/batch_process_notes.py --model_name \"meta-llama/Llama-3.1-8B-Instruct\" \\\n",
    "                                 --prompt_type \"five_shot_basic\" \\\n",
    "                                 --level 1 \\\n",
    "                                 --batch_size 10 \\\n",
    "                                 --start_index 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449f035",
   "metadata": {},
   "source": [
    "We can also evaluate models on the annotation dataset, this is done using another script:\n",
    "\n",
    "```console\n",
    "python scripts/evaluate_on_annotations.py --model_name \"meta-llama/Llama-3.1-8B-Instruct\" \\\n",
    "                                  --prompt_type \"five_shot_basic\" \\\n",
    "                                  --level 1 \\\n",
    "                                  --annotation_data \"data/raw/BRC-Data/annotated_BRC_referrals.csv\" \\\n",
    "                                  --sample_size 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de13e5",
   "metadata": {},
   "source": [
    "The evaluation system has two main components:\n",
    "\n",
    "- **Main evaluation script** (`evaluate_on_annotations.py`) -- This is the orchestrator that runs everything;\n",
    "- **Supporting utilies** (`utils/evaluation_helpers_lvl1.py`)-- These handle the specific tasks like model loading, SDoH extraction, and metric calculation.\n",
    "\n",
    "The evaluation script does the following for each sentence:\n",
    "\n",
    "1. **Extract**: Run the sentence through the SDoHExtractor\n",
    "2. **Format**: Convert the model's list output to a comparable string\n",
    "3. **Record**: Store both human and model labels plus metadata\n",
    "4. **Structure**: Build a DataFrame ready for multi-label metrics calculation\n",
    "\n",
    "Demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample annotated data:\n",
      "                                            Sentence  \\\n",
      "0  She needs help with food , toiletry and some cash   \n",
      "1  Mr PERSON was having support of a friend who h...   \n",
      "2  Isolated , housing concern impacting MH SU pre...   \n",
      "3      Equipment delivery to ensure safer discharge.   \n",
      "4  XXXX shopping FBG Patient is no longer driving...   \n",
      "\n",
      "                                Label  \n",
      "0  FoodInsecurity, FinancialSituation  \n",
      "1                       SocialSupport  \n",
      "2              SocialSupport, Housing  \n",
      "3                              NoSDoH  \n",
      "4                      Transportation  \n",
      "Loading meta-llama/Llama-3.1-8B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede2ba6f86824ece9215f51f8bd1d233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ meta-llama/Llama-3.1-8B-Instruct loaded successfully!\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 1 ---\n",
      "Text: She needs help with food , toiletry and some cash...\n",
      "Human labeled: FoodInsecurity, FinancialSituation\n",
      "Model predicted: FinancialSituation, FoodInsecurity\n",
      "Raw model response: <LIST>FinancialSituation, FoodInsecurity</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 2 ---\n",
      "Text: Mr PERSON was having support of a friend who had a car accid...\n",
      "Human labeled: SocialSupport\n",
      "Model predicted: SocialSupport, Transportation\n",
      "Raw model response: <LIST>SocialSupport, Transportation</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 3 ---\n",
      "Text: Isolated , housing concern impacting MH SU previously suppor...\n",
      "Human labeled: SocialSupport, Housing\n",
      "Model predicted: Housing, SocialSupport, SubstanceUse\n",
      "Raw model response: <LIST>Housing, SocialSupport, SubstanceUse</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sentence 4 ---\n",
      "Text: Equipment delivery to ensure safer discharge....\n",
      "Human labeled: NoSDoH\n",
      "Model predicted: NoSDoH\n",
      "Raw model response: <LIST>NoSDoH</LIST>\n",
      "Using chat template for meta-llama/llama-3.1-8b-instruct\n",
      "\n",
      "--- Sentence 5 ---\n",
      "Text: XXXX shopping FBG Patient is no longer driving , therefore n...\n",
      "Human labeled: Transportation\n",
      "Model predicted: FinancialSituation, SocialSupport, Transportation\n",
      "Raw model response: <LIST>Transportation, FinancialSituation, SocialSupport</LIST>\n",
      "\n",
      "Results DataFrame:\n",
      "                       original_label  \\\n",
      "0  FoodInsecurity, FinancialSituation   \n",
      "1                       SocialSupport   \n",
      "2              SocialSupport, Housing   \n",
      "3                              NoSDoH   \n",
      "4                      Transportation   \n",
      "\n",
      "                                    model_prediction  model_has_sdoh  \n",
      "0                 FinancialSituation, FoodInsecurity            True  \n",
      "1                      SocialSupport, Transportation            True  \n",
      "2               Housing, SocialSupport, SubstanceUse            True  \n",
      "3                                             NoSDoH           False  \n",
      "4  FinancialSituation, SocialSupport, Transportation            True  \n"
     ]
    }
   ],
   "source": [
    "from utils.SDoH_classification_helpers import SDoHExtractor\n",
    "from utils.model_helpers import load_instruction_model\n",
    "\n",
    "# Load annotated data (first few rows for demo)\n",
    "annotated_df = pd.read_csv(\"../data/raw/BRC-Data/annotated_BRC_referrals.csv\")\n",
    "sample_df = annotated_df.head(5)  # Just 5 sentences for demo\n",
    "sample_df.columns = ['CAS', 'Sentence', 'Label', 'Adverse', 'Comments']  # Standardise column names\n",
    "\n",
    "print(\"Sample annotated data:\")\n",
    "print(sample_df[['Sentence', 'Label']])\n",
    "\n",
    "# Load model\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tokenizer, model = load_instruction_model(model_name)\n",
    "\n",
    "# Create extractor\n",
    "extractor = SDoHExtractor(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt_type=\"five_shot_basic\",\n",
    "    level=1,\n",
    "    debug=True \n",
    ")\n",
    "\n",
    "# Process each sentence and build results\n",
    "results = []\n",
    "for idx, row in sample_df.iterrows():\n",
    "    sentence = str(row['Sentence']).strip()\n",
    "    \n",
    "    # Extract SDoH from sentence\n",
    "    extraction_result = extractor.extract_from_sentence(sentence)\n",
    "    factors = extraction_result[\"sdoh_factors\"]\n",
    "    \n",
    "    # Convert to comparison format\n",
    "    model_prediction = \", \".join(sorted(factors)) if factors and factors != [\"NoSDoH\"] else \"NoSDoH\"\n",
    "    \n",
    "    # Create result record (same structure as your evaluation script)\n",
    "    result = {\n",
    "        'cas': row['CAS'],\n",
    "        'sentence_number': idx + 1,\n",
    "        'original_sentence': sentence,\n",
    "        'original_label': row['Label'],\n",
    "        'model_prediction': model_prediction,\n",
    "        'model_factors_list': factors,\n",
    "        'model_has_sdoh': factors != [\"NoSDoH\"] and bool(factors),\n",
    "        'num_model_factors': len(factors) if factors != [\"NoSDoH\"] else 0,\n",
    "    }\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    # Show what happened\n",
    "    print(f\"\\n--- Sentence {idx + 1} ---\")\n",
    "    print(f\"Text: {sentence[:60]}...\")\n",
    "    print(f\"Human labeled: {row['Label']}\")\n",
    "    print(f\"Model predicted: {model_prediction}\")\n",
    "    if extraction_result.get(\"debug\"):\n",
    "        print(f\"Raw model response: {extraction_result['debug']['raw_response']}\")\n",
    "\n",
    "# Convert to DataFrame (ready for metrics calculation)\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd85d2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cas",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentence_number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "original_sentence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "original_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_prediction",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model_factors_list",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "model_has_sdoh",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "num_model_factors",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ef20ed23-0a11-4d71-ad1a-c2d11e261e6c",
       "rows": [
        [
         "0",
         "CAS-548353",
         "1",
         "She needs help with food , toiletry and some cash",
         "FoodInsecurity, FinancialSituation",
         "FinancialSituation, FoodInsecurity",
         "['FinancialSituation', 'FoodInsecurity']",
         "True",
         "2"
        ],
        [
         "1",
         "CAS-548411",
         "2",
         "Mr PERSON was having support of a friend who had a car accident , he supported Mr PERSON with food shopping",
         "SocialSupport",
         "SocialSupport, Transportation",
         "['SocialSupport', 'Transportation']",
         "True",
         "2"
        ],
        [
         "2",
         "CAS-548427",
         "3",
         "Isolated , housing concern impacting MH SU previously supported by the SP service",
         "SocialSupport, Housing",
         "Housing, SocialSupport, SubstanceUse",
         "['Housing', 'SocialSupport', 'SubstanceUse']",
         "True",
         "3"
        ],
        [
         "3",
         "CAS-548530",
         "4",
         "Equipment delivery to ensure safer discharge.",
         "NoSDoH",
         "NoSDoH",
         "['NoSDoH']",
         "False",
         "0"
        ],
        [
         "4",
         "CAS-548590",
         "5",
         "XXXX shopping FBG Patient is no longer driving , therefore needs an MP to take him shopping and to the bank to access his money",
         "Transportation",
         "FinancialSituation, SocialSupport, Transportation",
         "['Transportation', 'FinancialSituation', 'SocialSupport']",
         "True",
         "3"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cas</th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>original_sentence</th>\n",
       "      <th>original_label</th>\n",
       "      <th>model_prediction</th>\n",
       "      <th>model_factors_list</th>\n",
       "      <th>model_has_sdoh</th>\n",
       "      <th>num_model_factors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CAS-548353</td>\n",
       "      <td>1</td>\n",
       "      <td>She needs help with food , toiletry and some cash</td>\n",
       "      <td>FoodInsecurity, FinancialSituation</td>\n",
       "      <td>FinancialSituation, FoodInsecurity</td>\n",
       "      <td>[FinancialSituation, FoodInsecurity]</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAS-548411</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr PERSON was having support of a friend who h...</td>\n",
       "      <td>SocialSupport</td>\n",
       "      <td>SocialSupport, Transportation</td>\n",
       "      <td>[SocialSupport, Transportation]</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAS-548427</td>\n",
       "      <td>3</td>\n",
       "      <td>Isolated , housing concern impacting MH SU pre...</td>\n",
       "      <td>SocialSupport, Housing</td>\n",
       "      <td>Housing, SocialSupport, SubstanceUse</td>\n",
       "      <td>[Housing, SocialSupport, SubstanceUse]</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAS-548530</td>\n",
       "      <td>4</td>\n",
       "      <td>Equipment delivery to ensure safer discharge.</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>NoSDoH</td>\n",
       "      <td>[NoSDoH]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAS-548590</td>\n",
       "      <td>5</td>\n",
       "      <td>XXXX shopping FBG Patient is no longer driving...</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>FinancialSituation, SocialSupport, Transportation</td>\n",
       "      <td>[Transportation, FinancialSituation, SocialSup...</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cas  sentence_number  \\\n",
       "0  CAS-548353                1   \n",
       "1  CAS-548411                2   \n",
       "2  CAS-548427                3   \n",
       "3  CAS-548530                4   \n",
       "4  CAS-548590                5   \n",
       "\n",
       "                                   original_sentence  \\\n",
       "0  She needs help with food , toiletry and some cash   \n",
       "1  Mr PERSON was having support of a friend who h...   \n",
       "2  Isolated , housing concern impacting MH SU pre...   \n",
       "3      Equipment delivery to ensure safer discharge.   \n",
       "4  XXXX shopping FBG Patient is no longer driving...   \n",
       "\n",
       "                       original_label  \\\n",
       "0  FoodInsecurity, FinancialSituation   \n",
       "1                       SocialSupport   \n",
       "2              SocialSupport, Housing   \n",
       "3                              NoSDoH   \n",
       "4                      Transportation   \n",
       "\n",
       "                                    model_prediction  \\\n",
       "0                 FinancialSituation, FoodInsecurity   \n",
       "1                      SocialSupport, Transportation   \n",
       "2               Housing, SocialSupport, SubstanceUse   \n",
       "3                                             NoSDoH   \n",
       "4  FinancialSituation, SocialSupport, Transportation   \n",
       "\n",
       "                                  model_factors_list  model_has_sdoh  \\\n",
       "0               [FinancialSituation, FoodInsecurity]            True   \n",
       "1                    [SocialSupport, Transportation]            True   \n",
       "2             [Housing, SocialSupport, SubstanceUse]            True   \n",
       "3                                           [NoSDoH]           False   \n",
       "4  [Transportation, FinancialSituation, SocialSup...            True   \n",
       "\n",
       "   num_model_factors  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  3  \n",
       "3                  0  \n",
       "4                  3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bf239",
   "metadata": {},
   "source": [
    "After classifying SDoH from annotated sentences, the `calculate_multilabel_metrics` function from `utils/evaluation_helpers.py` does three main steps:\n",
    "\n",
    "1. Label parsing & preparation\n",
    "2. Binary matrix conversion\n",
    "\n",
    "    Example: If the labels are [\"Housing\", \"Employment\", \"Social Support\"]:\n",
    "    - [\"Housing\", \"Employment\"] becomes [1, 1, 0]\n",
    "    - [\"Housing\"] becomes [1, 0, 0]\n",
    "    - [\"NoSDoH\"] becomes [0, 0, 0]\n",
    "\n",
    "3. Return multi-Label metrics\n",
    "\n",
    "    The function calculates four types of metrics:\n",
    "    - Example-based: How well does the model predict the exact set of labels for each sentence?\n",
    "    - Label-based: How well does the model perform on each individual label?\n",
    "    - Per-label: Performance breakdown for each SDoH factor\n",
    "    - Statistics: Overall dataset characteristics\n",
    "\n",
    "I can now dive deeper into the metrics used for multi-label classification.\n",
    "\n",
    "1. **Example-Based Metrics (averaged across sentences)**. These look at how well the model predicts the complete set of labels for each sentence:\n",
    "\n",
    "    - Exact Match Ratio (Subset Accuracy): Percentage where model prediction exactly matches human annotation. [\"Housing\", \"Employment\"] == [\"Housing\", \"Employment\"] ✓ = 1.0; [\"Housing\"] vs [\"Housing\", \"Employment\"] ✗ = 0.0\n",
    "    - Hamming Loss: Fraction of wrong label assignments (lower is better). Counts individual label mistakes across all positions; If you have 3 possible labels and get 1 wrong: hamming_loss = 1/3 = 0.33.\n",
    "    - Additional metrics: Example-based Precision/Recall/F1; Jaccard Index\n",
    "2. **Label-Based Metrics (averaged across labels)**. These treat each SDoH factor as a separate binary classification problem:\n",
    "\n",
    "    - Macro-averaged (treats all labels equally). Calculate precision/recall/F1 for each label separately; and average them (rare labels get same weight as common ones)\n",
    "    - Micro-averaged (weighted by frequency). Pool all true/false positives across labels; more influenced by common labels.\n",
    "\n",
    "3. **Per-Label Performance**. Individual precision/recall/F1 for each SDoH factor:\n",
    "4. **Dataset Statistics**\n",
    "\n",
    "    - Label Cardinality: Average number of labels per sentence\n",
    "    - Label Density: Cardinality divided by total possible labels\n",
    "    - Coverage: How many different labels appear at least once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e92f9f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
