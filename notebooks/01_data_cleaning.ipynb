{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e413d4d",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6cf3e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c7d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38c32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a880eb",
   "metadata": {},
   "source": [
    "## Cleaning referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cleaning_helpers import clean_na_variations, remove_duplicate_sentences_per_case\n",
    "\n",
    "brc_referrals_raw = pd.read_csv(\"../data/raw/BRC-Data/Cases_depersonalised.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149581f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (181085, 19)\n",
      "Columns: ['Area', 'Scheme', 'Case Reference', 'Assessment Result', 'Case Status', 'Referral Date/Time', 'End Date Case', 'Has Disability', 'Has Risk', 'Risk Type', 'Unique Case', 'IMD_decile', 'Country', 'Age', 'Gender', 'Ethnicity', 'Disability', 'Living Arrangements', 'Referral Notes (depersonalised)']\n",
      "\n",
      "Original referral notes missing values: 30621\n",
      "After removing missing referral notes: (150464, 19)\n",
      "After removing NA variations: (150464, 19) (removed 0 rows) \n",
      "\n",
      "Removing duplicate sentences within cases...\n",
      "Original sentences: 340393\n",
      "Unique sentences: 182168\n",
      "Sentences removed: 158225\n",
      "\n",
      "Final cleaned data shape: (99560, 19)\n",
      "Number of unique referral notes: 51658\n",
      "\n",
      "Cleaned data saved to: ../data/processed/BRC_referrals_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data shape:\", brc_referrals_raw.shape)\n",
    "print(\"Columns:\", brc_referrals_raw.columns.tolist())\n",
    "\n",
    "# 1. Remove missing values for referral notes\n",
    "print(f\"\\nOriginal referral notes missing values: {brc_referrals_raw['Referral Notes (depersonalised)'].isnull().sum()}\")\n",
    "\n",
    "brc_cleaned = brc_referrals_raw.dropna(subset=['Referral Notes (depersonalised)']).copy()\n",
    "print(f\"After removing missing referral notes: {brc_cleaned.shape}\")\n",
    "\n",
    "# 2. Apply NA cleaning to referral notes\n",
    "brc_cleaned['Referral Notes (depersonalised)'] = brc_cleaned['Referral Notes (depersonalised)'].apply(clean_na_variations)\n",
    "    \n",
    "# Remove rows where referral notes became NaN after cleaning\n",
    "before_na_clean = brc_cleaned.shape[0]\n",
    "brc_cleaned = brc_cleaned.dropna(subset=['Referral Notes (depersonalised)'])\n",
    "print(f\"After removing NA variations: {brc_cleaned.shape} (removed {before_na_clean - brc_cleaned.shape[0]} rows) \\n\")\n",
    "\n",
    "# 3. Remove duplicate sentences within multiple notes corresponding to a single Case Reference\n",
    "# As done in Keloth et al. (2025)\n",
    "brc_final = remove_duplicate_sentences_per_case(brc_cleaned)\n",
    "print(f\"\\nFinal cleaned data shape: {brc_final.shape}\")\n",
    "print(f\"Number of unique referral notes: {brc_final['Referral Notes (depersonalised)'].nunique()}\")\n",
    "\n",
    "# Save the cleaned data\n",
    "output_path = Path(\"../data/processed/BRC_referrals_cleaned.csv\")\n",
    "brc_final.to_csv(output_path, index=False)\n",
    "print(f\"\\nCleaned data saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd65ed4",
   "metadata": {},
   "source": [
    "## Joining with outcomes datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53035338",
   "metadata": {},
   "outputs": [],
   "source": [
    "referrals_cleaned = pd.read_csv(\"../data/processed/BRC_referrals_cleaned.csv\")\n",
    "hiu_raw = pd.read_csv(\"../data/raw/BRC-Data/HIU_depersonalised.csv\")\n",
    "snap_raw = pd.read_csv(\"../data/raw/BRC-Data/SNAP_depersonalised.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea27c3b",
   "metadata": {},
   "source": [
    "### Check overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b2d3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes:\n",
      "Referrals: 99,560\n",
      "HIU: 1,430\n",
      "SNAP: 1,305\n",
      "\n",
      "Overlaps:\n",
      "Referrals ∩ HIU: 1,110\n",
      "Referrals ∩ SNAP: 1,096\n",
      "HIU ∩ SNAP: 0\n",
      "All three: 0\n"
     ]
    }
   ],
   "source": [
    "# Standardize case reference columns\n",
    "referrals_cleaned['case_ref'] = referrals_cleaned['Case Reference']\n",
    "hiu_raw['case_ref'] = 'CAS-' + hiu_raw['Q2.1. CAS-'].astype(str).str.replace('.0', '', regex=False)\n",
    "snap_raw['case_ref'] = snap_raw['BRM case number:']\n",
    "\n",
    "# Get case reference sets\n",
    "ref_cases = set(referrals_cleaned['case_ref'].dropna())\n",
    "hiu_cases = set(hiu_raw['case_ref'].dropna())\n",
    "snap_cases = set(snap_raw['case_ref'].dropna())\n",
    "\n",
    "# Print overlap counts\n",
    "print(\"Dataset Sizes:\")\n",
    "print(f\"Referrals: {len(ref_cases):,}\")\n",
    "print(f\"HIU: {len(hiu_cases):,}\")\n",
    "print(f\"SNAP: {len(snap_cases):,}\")\n",
    "\n",
    "print(\"\\nOverlaps:\")\n",
    "print(f\"Referrals ∩ HIU: {len(ref_cases & hiu_cases):,}\")\n",
    "print(f\"Referrals ∩ SNAP: {len(ref_cases & snap_cases):,}\")\n",
    "print(f\"HIU ∩ SNAP: {len(hiu_cases & snap_cases):,}\")\n",
    "print(f\"All three: {len(ref_cases & hiu_cases & snap_cases):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb837c",
   "metadata": {},
   "source": [
    "### Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8814f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets with standardized case reference\n",
    "referrals = referrals_cleaned.copy()\n",
    "referrals['case_ref'] = referrals['Case Reference']\n",
    "\n",
    "hiu = hiu_raw.copy()\n",
    "hiu['case_ref'] = 'CAS-' + hiu['Q2.1. CAS-'].astype(str).str.replace('.0', '', regex=False)\n",
    "\n",
    "snap = snap_raw.copy()\n",
    "snap['case_ref'] = snap['BRM case number:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1cbfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged dataset saved to: ../data/processed/BRC_referrals_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# Set case_ref as index for merging\n",
    "referrals.set_index('case_ref', inplace=True)\n",
    "hiu.set_index('case_ref', inplace=True)\n",
    "snap.set_index('case_ref', inplace=True)\n",
    "\n",
    "# Merge HIU and SNAP into referrals dataset\n",
    "merged = referrals.join(hiu, how='left', rsuffix='_hiu').join(snap, how='left', rsuffix='_snap')\n",
    "\n",
    "# Create dataset source indicator variables\n",
    "merged['has_referral'] = True  # All cases have referral data since we're using left join\n",
    "merged['has_hiu'] = merged['Q2.1. CAS-'].notna()\n",
    "merged['has_snap'] = merged['BRM case number:'].notna()\n",
    "\n",
    "# Create combined dataset source variable\n",
    "merged['dataset_sources'] = (\n",
    "    merged['has_referral'].astype(str).replace({'True': 'Referral', 'False': ''}) + \n",
    "    (merged['has_hiu'].apply(lambda x: '+HIU' if x else '')) +\n",
    "    (merged['has_snap'].apply(lambda x: '+SNAP' if x else ''))\n",
    ")\n",
    "\n",
    "# Reset index to get case_ref back as column\n",
    "merged.reset_index(inplace=True)\n",
    "\n",
    "# Save the merged dataset\n",
    "output_merged_path = Path(\"../data/processed/BRC_referrals_merged.csv\")\n",
    "merged.to_csv(output_merged_path, index=False)\n",
    "print(f\"\\nMerged dataset saved to: {output_merged_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36cacf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (100882, 182)\n",
      "\n",
      "Dataset source combinations:\n",
      "dataset_sources\n",
      "Referral         97354\n",
      "Referral+HIU      1880\n",
      "Referral+SNAP     1648\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data availability:\n",
      "Has referral data: 100,882\n",
      "Has HIU data: 1,880\n",
      "Has SNAP data: 1,648\n"
     ]
    }
   ],
   "source": [
    "print(f\"Merged dataset shape: {merged.shape}\")\n",
    "print(f\"\\nDataset source combinations:\")\n",
    "print(merged['dataset_sources'].value_counts())\n",
    "\n",
    "print(f\"\\nData availability:\")\n",
    "print(f\"Has referral data: {merged['has_referral'].sum():,}\")\n",
    "print(f\"Has HIU data: {merged['has_hiu'].sum():,}\")\n",
    "print(f\"Has SNAP data: {merged['has_snap'].sum():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
