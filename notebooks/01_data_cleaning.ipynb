{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e413d4d",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6cf3e",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c7d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38c32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf5729",
   "metadata": {},
   "source": [
    "## 1. Pre-cleaning BRC data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9bee6b",
   "metadata": {},
   "source": [
    "### 1.1 Duplicate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "606f331f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and standardize case references\n",
    "datasets = {\n",
    "    'referrals': pd.read_csv(\"../data/raw/BRC-Data/Cases_depersonalised.csv\"),\n",
    "    'hiu': pd.read_csv(\"../data/raw/BRC-Data/HIU_depersonalised.csv\"),\n",
    "    'snap': pd.read_csv(\"../data/raw/BRC-Data/SNAP_depersonalised.csv\")\n",
    "}\n",
    "\n",
    "# Standardize case reference columns\n",
    "datasets['referrals']['case_ref'] = datasets['referrals']['Case Reference']\n",
    "datasets['hiu']['case_ref'] = 'CAS-' + datasets['hiu']['Q2.1. CAS-'].astype(str).str.replace('.0', '', regex=False)\n",
    "datasets['snap']['case_ref'] = datasets['snap']['BRM case number:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DUPLICATE ANALYSIS BEFORE CLEANING ===\")\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n{name.upper()} Dataset:\")\n",
    "    print(f\"  Total rows: {len(df):,}\")\n",
    "    print(f\"  Unique case_ref: {df['case_ref'].nunique():,}\")\n",
    "    \n",
    "    # Define columns to exclude from duplication analysis (depersonalized/randomized)\n",
    "    if name == 'referrals':\n",
    "        # For referrals: only consider case_ref and referral notes\n",
    "        analysis_cols = ['case_ref', 'Referral Notes (depersonalised)', 'Referral Date/Time']\n",
    "        available_cols = [col for col in analysis_cols if col in df.columns]\n",
    "        print(f\"  Analysing duplicates based on: {available_cols}\")\n",
    "    elif name == 'snap':\n",
    "        # Exclude: Has Disability, IMD Decile, Country, Age, Gender, Ethnicity, Living Arrangements\n",
    "        exclude_cols = ['Has Disability', 'IMD Decile', 'Country', 'Age', 'Gender', 'Ethnicity', 'Living Arrangements']\n",
    "        available_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "        print(f\"  Analysing duplicates excluding {len(exclude_cols)} depersonalised columns\")\n",
    "    elif name == 'hiu':\n",
    "        # Exclude: Age, Gender, Ethnicity, Living Arrangements\n",
    "        exclude_cols = ['Age', 'Gender', 'Ethnicity', 'Living Arrangements']\n",
    "        available_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "        print(f\"  Analysing duplicates excluding {len(exclude_cols)} depersonalised columns\")\n",
    "    \n",
    "    # Check for perfect duplicates based on relevant columns only\n",
    "    perfect_duplicates = df.duplicated(subset=available_cols).sum()\n",
    "    print(f\"  Perfect duplicates (relevant columns): {perfect_duplicates:,}\")\n",
    "    \n",
    "    # Check for duplicates by case_ref only\n",
    "    case_ref_duplicates = df['case_ref'].duplicated().sum()\n",
    "    print(f\"  Duplicate case_ref: {case_ref_duplicates:,}\")\n",
    "    \n",
    "    if case_ref_duplicates > 0:\n",
    "        # Show examples of duplicate case_ref: Show top 5 by count\n",
    "        duplicate_cases = df[df['case_ref'].duplicated(keep=False)]['case_ref'].value_counts().head(5)\n",
    "        print(f\"  Top 5 duplicate case_ref by count:\")\n",
    "        for case_ref, count in duplicate_cases.items():\n",
    "            print(f\"    {case_ref}: {count} rows\")\n",
    "        \n",
    "        # Check if duplicate case_ref have identical relevant data - CHANGED: Use highest count case\n",
    "        highest_count_case = duplicate_cases.index[0]  # This is now the case with most duplicates\n",
    "        duplicate_rows = df[df['case_ref'] == highest_count_case]\n",
    "        \n",
    "        # Check duplicates based on relevant columns only\n",
    "        duplicate_subset = duplicate_rows[available_cols]\n",
    "        identical_duplicates = duplicate_subset.duplicated().sum()\n",
    "        \n",
    "        print(f\"    For case {highest_count_case}: {identical_duplicates}/{len(duplicate_rows)-1} duplicates are identical (relevant data)\")\n",
    "        \n",
    "        # Show what's different in duplicate rows (if any) - only relevant columns\n",
    "        if identical_duplicates < len(duplicate_rows) - 1:\n",
    "            print(f\"    Non-identical relevant columns for {highest_count_case}:\")\n",
    "            for col in available_cols:\n",
    "                if col in duplicate_rows.columns:\n",
    "                    unique_vals = duplicate_rows[col].nunique()\n",
    "                    if unique_vals > 1:\n",
    "                        values = duplicate_rows[col].tolist()\n",
    "                        # For referral notes, show preview\n",
    "                        if col == 'Referral Notes (depersonalised)':\n",
    "                            values = [str(v)[:50] + \"...\" if len(str(v)) > 50 else str(v) for v in values]\n",
    "                        print(f\"      {col}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbeb98f",
   "metadata": {},
   "source": [
    "### 1.2. Pre-cleaning referrals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e46c7b",
   "metadata": {},
   "source": [
    "I start with the pre-cleaning of referrals.\n",
    "\n",
    "1. I remove identical rows based on: ['case_ref', 'Referral Notes (depersonalised)', 'Referral Date/Time']. Those are pure duplicates (other columns might be different due to the depersonalisation).\n",
    "\n",
    "Then, for each CAS which has multiple rows (most likely on different dates):\n",
    "\n",
    "2. I create two columns: one with the number of observations, and one with the date range of those observations;\n",
    "3. Then, if one or some of the rows have a non-NA referral, I remove the rows which don't. \n",
    "4. Finally, if all observations have the same referrals, or if none of the observations have a referral, I only keep the most recent row (the columns created earlier will keep the other relevant information).\n",
    "\n",
    "The only duplicated CAS left will be those with different referrals on different dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_cleaning.data_cleaning_helpers import clean_referrals_dataset\n",
    "\n",
    "# Load the referrals data\n",
    "referrals_df = datasets['referrals'].copy()\n",
    "\n",
    "# Clean the dataset\n",
    "referrals_cleaned = clean_referrals_dataset(referrals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4d8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ANALYSING REFERRALS BY DATE PATTERNS ===\")\n",
    "\n",
    "# Convert date column to datetime if not already\n",
    "referrals_cleaned['Referral Date/Time'] = pd.to_datetime(referrals_cleaned['Referral Date/Time'], errors='coerce')\n",
    "referrals_cleaned['referral_date'] = referrals_cleaned['Referral Date/Time'].dt.date\n",
    "\n",
    "# Cases with multiple referrals\n",
    "multi_referral_cases = referrals_cleaned['case_ref'].value_counts()\n",
    "multi_referral_cases = multi_referral_cases[multi_referral_cases > 1]\n",
    "\n",
    "print(f\"Cases with multiple referrals: {len(multi_referral_cases):,}\")\n",
    "print(f\"Cases with single referral: {referrals_cleaned['case_ref'].nunique() - len(multi_referral_cases):,}\")\n",
    "\n",
    "# Analyze date patterns for multi-referral cases\n",
    "print(f\"\\n=== DATE PATTERNS FOR {len(multi_referral_cases):,} MULTI-REFERRAL CASES ===\")\n",
    "\n",
    "same_date_stats = []\n",
    "for case_ref in multi_referral_cases.index:\n",
    "    case_data = referrals_cleaned[referrals_cleaned['case_ref'] == case_ref].copy()\n",
    "    \n",
    "    # Count unique dates for this case\n",
    "    unique_dates = case_data['referral_date'].nunique()\n",
    "    total_referrals = len(case_data)\n",
    "    \n",
    "    same_date_stats.append({\n",
    "        'case_ref': case_ref,\n",
    "        'total_referrals': total_referrals,\n",
    "        'unique_dates': unique_dates,\n",
    "        'all_same_date': unique_dates == 1,\n",
    "        'multiple_dates': unique_dates > 1\n",
    "    })\n",
    "\n",
    "same_date_df = pd.DataFrame(same_date_stats)\n",
    "\n",
    "# Summary statistics\n",
    "all_same_date = same_date_df['all_same_date'].sum()\n",
    "multiple_dates = same_date_df['multiple_dates'].sum()\n",
    "\n",
    "print(f\"Cases where ALL referrals are on the SAME date: {all_same_date:,} ({all_same_date/len(multi_referral_cases)*100:.1f}%)\")\n",
    "print(f\"Cases with referrals on MULTIPLE dates: {multiple_dates:,} ({multiple_dates/len(multi_referral_cases)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7dde9a",
   "metadata": {},
   "source": [
    "For cases which have multiple observations with DIFFERENT referrals, they are always done on the same date. I decide to keep the longest referral, to keep the maximum information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e082643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_cleaning.data_cleaning_helpers import consolidate_referrals_longest\n",
    "\n",
    "# Apply consolidation\n",
    "referrals_consolidated = consolidate_referrals_longest(referrals_cleaned)\n",
    "\n",
    "# Save consolidated dataset\n",
    "referrals_consolidated.to_csv(\"../data/processed/referrals_cleaned.csv\", index=False)\n",
    "print(f\"\\nConsolidated referrals saved to: ../data/processed/referrals_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81666df",
   "metadata": {},
   "source": [
    "### 1.3. Pre-cleaning SNAP data & merging with referrals\n",
    "\n",
    "I start with **SNAP** (Support at Home, Care at Home, Hospital at Home, and Social Prescribing services).\n",
    "\n",
    "These services have started using an outcomes framework called hiu (Social Needs and Preferences), which was only introduced in late 2024.\n",
    "\n",
    "The pre-cleaning of SNAP is done as follows:\n",
    "\n",
    "1. I removed perfect duplicates based on columns that were not randomised in the depersonalisation process.\n",
    "\n",
    "Then, I noticed that CAS have either one or two observations (not more). These correspond to observations at the start and / or at the end of support from the BRC. I get a brief overview.\n",
    "\n",
    "2. For each case, I determine what type of valid assessments are available, only counting valid where 'Possible to record outcomes:' == 'Yes'. \n",
    "3. I then create a summary for each case showing:\n",
    "    - Total number of assessments\n",
    "    - Whether valid baseline assessment exists (timepoint 1.0 + recordable outcomes)\n",
    "    - Whether valid post-support assessment exists (timepoint 2.0 + recordable outcomes)\n",
    "    - Whether case has both valid assessments (complete usable pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b26266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_cleaning.data_cleaning_helpers import clean_snap_dataset\n",
    "\n",
    "snap_df = datasets['snap'].copy()\n",
    "\n",
    "# Clean the SNAP dataset\n",
    "snap_cleaned = clean_snap_dataset(snap_df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "snap_cleaned.to_csv(\"../data/processed/snap_cleaned.csv\", index=False)\n",
    "print(f\"\\nCleaned dataset saved to: ../data/processed/snap_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbec9b1",
   "metadata": {},
   "source": [
    "**Merging with SNAP & referrals**\n",
    "\n",
    "I now proceed to creating a merged dataset with referrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f50245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_referrals_with_snap():\n",
    "    \"\"\"\n",
    "    Merge referrals (1 row per case) with SNAP data (1-2 rows per case).\n",
    "    Only keeps cases that appear in both datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== MERGING REFERRALS WITH SNAP DATA ===\")\n",
    "    \n",
    "    # Load datasets\n",
    "    referrals_df = pd.read_csv(\"../data/processed/referrals_cleaned.csv\")\n",
    "    snap_df = pd.read_csv(\"../data/processed/snap_cleaned.csv\")\n",
    "    \n",
    "    print(f\"Referrals dataset: {len(referrals_df):,} rows, {referrals_df['case_ref'].nunique():,} unique cases\")\n",
    "    print(f\"SNAP dataset: {len(snap_df):,} rows, {snap_df['case_ref'].nunique():,} unique cases\")\n",
    "    \n",
    "    # Find cases that appear in both datasets\n",
    "    referrals_cases = set(referrals_df['case_ref'])\n",
    "    snap_cases = set(snap_df['case_ref'])\n",
    "    \n",
    "    common_cases = referrals_cases.intersection(snap_cases)\n",
    "    \n",
    "    print(f\"\\nCases in both datasets: {len(common_cases):,}\")\n",
    "    print(f\"Cases only in referrals: {len(referrals_cases - snap_cases):,}\")\n",
    "    print(f\"Cases only in SNAP: {len(snap_cases - referrals_cases):,}\")\n",
    "    \n",
    "    # Filter both datasets to common cases only\n",
    "    referrals_common = referrals_df[referrals_df['case_ref'].isin(common_cases)].copy()\n",
    "    snap_common = snap_df[snap_df['case_ref'].isin(common_cases)].copy()\n",
    "    \n",
    "    print(f\"\\nAfter filtering to common cases:\")\n",
    "    print(f\"Referrals: {len(referrals_common):,} rows\")\n",
    "    print(f\"SNAP: {len(snap_common):,} rows\")\n",
    "    \n",
    "    # Merge: each referral row will be duplicated for each SNAP row of the same case\n",
    "    merged_df = snap_common.merge(referrals_common, on='case_ref', how='inner', suffixes=('_snap', '_referral'))\n",
    "    \n",
    "    print(f\"\\nMerged dataset: {len(merged_df):,} rows, {merged_df['case_ref'].nunique():,} unique cases\")\n",
    "    \n",
    "    # Show structure breakdown\n",
    "    rows_per_case = merged_df['case_ref'].value_counts()\n",
    "    print(f\"\\nRows per case in merged dataset:\")\n",
    "    print(f\"  1 row (baseline only): {(rows_per_case == 1).sum():,} cases\")\n",
    "    print(f\"  2 rows (baseline + outcome): {(rows_per_case == 2).sum():,} cases\")\n",
    "    if (rows_per_case > 2).any():\n",
    "        print(f\"  >2 rows (unexpected): {(rows_per_case > 2).sum():,} cases\")\n",
    "    \n",
    "    # Show SNAP assessment validity breakdown for merged cases\n",
    "    if 'has_both' in merged_df.columns:\n",
    "        cases_with_both = merged_df.drop_duplicates('case_ref')['has_both'].sum()\n",
    "        cases_baseline_only = merged_df.drop_duplicates('case_ref')['has_valid_baseline'].sum() - cases_with_both\n",
    "        \n",
    "        print(f\"\\nSNAP assessment validity in merged dataset:\")\n",
    "        print(f\"  Cases with valid baseline + outcome: {cases_with_both:,}\")\n",
    "        print(f\"  Cases with valid baseline only: {cases_baseline_only:,}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Perform the merge\n",
    "merged_referrals_snap = merge_referrals_with_snap()\n",
    "\n",
    "# Save merged dataset\n",
    "merged_referrals_snap.to_csv(\"../data/processed/merged_referrals_snap.csv\", index=False)\n",
    "print(f\"\\nMerged dataset saved to: ../data/processed/merged_referrals_snap.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a55cdfc",
   "metadata": {},
   "source": [
    "Let's now check the completeness of the data for cases which have both baseline and post-support observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc7093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data completeness for key domains\n",
    "key_domains = ['Control (QLC)', 'Personal cleanliness (QLC)', 'Food and drink (QLC)', \n",
    "               'Personal safety (QLC)', 'Social Participation (QLC)', 'Occupation (QLC)', \n",
    "               'Accommodation (QLC)', 'Dignity 1 (QLC)', 'snap_Medication (QLC)', 'Finances (QLC)']\n",
    "\n",
    "# Filter rows with both baseline and outcome\n",
    "filtered_snap = merged_referrals_snap[merged_referrals_snap['has_both']]\n",
    "\n",
    "print(f\"\\n=== DATA COMPLETENESS ===\")\n",
    "for domain in key_domains:\n",
    "    if domain in filtered_snap.columns:\n",
    "        completeness = filtered_snap[domain].notna().mean()\n",
    "        print(f\"{domain}: {completeness:.1%} complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc008f",
   "metadata": {},
   "source": [
    "### 1.4. Pre-cleaning HIU data & merging with referrals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab904b",
   "metadata": {},
   "source": [
    "I move on to **HIU** (High Intensity Use service for people frequently attending A&E).\n",
    "\n",
    "1. Same as before, I first remove perfect duplicates, excluding the 4 depersonalized columns (Age, Gender, Ethnicity, Living Arrangements) from duplicate detection since these were randomised.\n",
    "2. I then identify valid assessments by 'Time Points'. This step uses the 'Q6. Why wasn't it possible to record outcomes for this client?' column - if this is filled out, outcomes were NOT recordable, so we need this to be empty/NaN for valid assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_cleaning.data_cleaning_helpers import clean_hiu_dataset\n",
    "\n",
    "hiu_df = datasets['hiu'].copy()\n",
    "\n",
    "hiu_cleaned = clean_hiu_dataset(hiu_df)\n",
    "\n",
    "# Save cleaned dataset\n",
    "hiu_cleaned.to_csv(\"../data/processed/hiu_cleaned.csv\", index=False)\n",
    "print(f\"\\nCleaned dataset saved to: ../data/processed/hiu_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data completeness for key domains\n",
    "key_domains2 = ['Change in Activation', 'Change in Wellbeing', 'Change in Housing', \n",
    "               'Change in Finance', 'Change in Loneliness', 'Change in Social Value']\n",
    "\n",
    "# Filter rows with both baseline and outcome\n",
    "filtered_hiu = hiu_cleaned[hiu_cleaned['has_both']]\n",
    "\n",
    "print(f\"\\n=== DATA COMPLETENESS ===\")\n",
    "for domain in key_domains2:\n",
    "    if domain in filtered_hiu.columns:\n",
    "        completeness = filtered_hiu[domain].notna().mean()\n",
    "        print(f\"{domain}: {completeness:.1%} complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3081400d",
   "metadata": {},
   "source": [
    "**Merging HIU & referrals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_referrals_with_hiu():\n",
    "    \"\"\"\n",
    "    Merge referrals (1 row per case) with HIU data (multiple rows per case).\n",
    "    Only keeps cases that appear in both datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== MERGING REFERRALS WITH HIU DATA ===\")\n",
    "    \n",
    "    # Load datasets\n",
    "    referrals_df = pd.read_csv(\"../data/processed/referrals_cleaned.csv\")\n",
    "    hiu_df = pd.read_csv(\"../data/processed/hiu_cleaned.csv\")\n",
    "    \n",
    "    print(f\"Referrals dataset: {len(referrals_df):,} rows, {referrals_df['case_ref'].nunique():,} unique cases\")\n",
    "    print(f\"HIU dataset: {len(hiu_df):,} rows, {hiu_df['case_ref'].nunique():,} unique cases\")\n",
    "    \n",
    "    # Find cases that appear in both datasets\n",
    "    referrals_cases = set(referrals_df['case_ref'])\n",
    "    hiu_cases = set(hiu_df['case_ref'])\n",
    "    \n",
    "    common_cases = referrals_cases.intersection(hiu_cases)\n",
    "    \n",
    "    print(f\"\\nCases in both datasets: {len(common_cases):,}\")\n",
    "    print(f\"Cases only in referrals: {len(referrals_cases - hiu_cases):,}\")\n",
    "    print(f\"Cases only in HIU: {len(hiu_cases - referrals_cases):,}\")\n",
    "    \n",
    "    # Filter both datasets to common cases only\n",
    "    referrals_common = referrals_df[referrals_df['case_ref'].isin(common_cases)].copy()\n",
    "    hiu_common = hiu_df[hiu_df['case_ref'].isin(common_cases)].copy()\n",
    "    \n",
    "    print(f\"\\nAfter filtering to common cases:\")\n",
    "    print(f\"Referrals: {len(referrals_common):,} rows\")\n",
    "    print(f\"HIU: {len(hiu_common):,} rows\")\n",
    "    \n",
    "    # Merge: each referral row will be duplicated for each HIU row of the same case\n",
    "    merged_df = hiu_common.merge(referrals_common, on='case_ref', how='inner', suffixes=('_hiu', '_referral'))\n",
    "    \n",
    "    print(f\"\\nMerged dataset: {len(merged_df):,} rows, {merged_df['case_ref'].nunique():,} unique cases\")\n",
    "    \n",
    "    # Show structure breakdown\n",
    "    rows_per_case = merged_df['case_ref'].value_counts()\n",
    "    print(f\"\\nRows per case in merged dataset:\")\n",
    "    print(f\"  1 row (baseline only): {(rows_per_case == 1).sum():,} cases\")\n",
    "    print(f\"  2 rows (baseline + outcome): {(rows_per_case == 2).sum():,} cases\")\n",
    "    if (rows_per_case > 2).any():\n",
    "        print(f\"  >2 rows (unexpected): {(rows_per_case > 2).sum():,} cases\")\n",
    "    \n",
    "    # Show HIU assessment validity breakdown for merged cases\n",
    "    if 'has_both' in merged_df.columns:\n",
    "        cases_with_both = merged_df.drop_duplicates('case_ref')['has_both'].sum()\n",
    "        cases_baseline_only = merged_df.drop_duplicates('case_ref')['has_valid_baseline'].sum() - cases_with_both\n",
    "        \n",
    "        print(f\"\\HIU assessment validity in merged dataset:\")\n",
    "        print(f\"  Cases with valid baseline + outcome: {cases_with_both:,}\")\n",
    "        print(f\"  Cases with valid baseline only: {cases_baseline_only:,}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Perform the merge\n",
    "merged_referrals_hiu = merge_referrals_with_hiu()\n",
    "\n",
    "# Save merged dataset\n",
    "merged_referrals_hiu.to_csv(\"../data/processed/merged_referrals_hiu.csv\", index=False)\n",
    "print(f\"\\nMerged dataset saved to: ../data/processed/merged_referrals_hiu.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fa425",
   "metadata": {},
   "source": [
    "## 2. SDoH cleaning SNAP & HIU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d07e0",
   "metadata": {},
   "source": [
    "### 2.1. SNAP final cleaning\n",
    "\n",
    "The SNAP dataset was cleaned to identify reliable labels for social determinants of health (SDoH) to support referral text analysis. The cleaning process involved the following steps:\n",
    "\n",
    "1. **Domain Selection**: We focused on the following SDoH domains:\n",
    "   - Housing\n",
    "   - Finances\n",
    "   - Loneliness\n",
    "   - Food insecurity\n",
    "\n",
    "2. **Binary Need Labels**: For each domain, we used or derived a binary variable indicating whether a need was present:\n",
    "   - Pre-existing binary fields were used for housing, food insecurity, and loneliness.\n",
    "   - A binary variable for finance need was created from the `\"Finances:\"` perception column using keyword-based classification.\n",
    "\n",
    "3. **Perception Consistency Checks**:\n",
    "   - For each domain, a qualitative perception column was also included:\n",
    "     - `Clean home` (housing), `Social life:` (loneliness), `Food & drink:` (food insecurity)\n",
    "   - We flagged cases where the perception conflicted with the binary label (e.g., \"adequate\" perception but labeled as having a need).\n",
    "   - Any row with such an inconsistency was excluded.\n",
    "\n",
    "4. **Exclusion Criteria**: Rows were dropped if:\n",
    "   - `referral_note` was missing\n",
    "   - The row contained inconsistency between perception and binary need\n",
    "   - No valid baseline assessment was available\n",
    "\n",
    "5. **Final Output**: The resulting dataset (`snap_final.csv`) provides high-quality binary indicators for housing, finances, loneliness, and food insecurity needs, alongside clean referral text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean\n",
    "merged_snap_df = pd.read_csv(\"../data/processed/merged/merged_referrals_snap.csv\")\n",
    "merged_snap_df.columns = merged_snap_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280762/1598644304.py:39: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  snap_subset[col] = snap_subset[col].replace({\"Need\": 1, \"No Need\": 0}).infer_objects(copy=False)\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 1: Subsetting columns ---\n",
    "referral_col = {\n",
    "    \"Referral Notes (depersonalised)\": \"referral_note\"\n",
    "}\n",
    "\n",
    "binary_sdoh = {\n",
    "    \"Accommodation cleanliness and comfort need\": \"housing_need\",\n",
    "    \"Social interaction need\": \"loneliness_need\",\n",
    "    \"Food and drink need\": \"food_insecurity_need\",\n",
    "    # \"Finances need\": \"finances_need\"  # Excluded since not in data\n",
    "}\n",
    "\n",
    "perception_sdoh = {\n",
    "    \"Clean home\": \"housing_perception\",\n",
    "    \"Social life:\": \"social_perception\",\n",
    "    \"Food & drink:\": \"food_perception\",\n",
    "    \"Finances:\": \"finances_perception\"\n",
    "}\n",
    "\n",
    "# Meta columns\n",
    "meta_cols = [\"case_ref\", \"Timepoint\", \"has_valid_baseline\", \"has_valid_post_support\"]\n",
    "\n",
    "# Full subset\n",
    "snap_subset = merged_snap_df[\n",
    "    meta_cols + list(referral_col.keys()) + list(binary_sdoh.keys()) + list(perception_sdoh.keys())\n",
    "].copy()\n",
    "\n",
    "# Rename columns\n",
    "snap_subset = snap_subset.rename(columns={**referral_col, **binary_sdoh, **perception_sdoh})\n",
    "\n",
    "# Filter to baseline\n",
    "snap_subset = snap_subset[snap_subset[\"Timepoint\"] == 1]\n",
    "\n",
    "# Convert binary SDoH indicators\n",
    "for col in binary_sdoh.values():\n",
    "    snap_subset[col] = snap_subset[col].replace({\"Need\": 1, \"No Need\": 0}).infer_objects(copy=False)\n",
    "\n",
    "# Drop rows where all binary SDoH are missing\n",
    "snap_subset = snap_subset.dropna(subset=list(binary_sdoh.values()), how=\"all\")\n",
    "\n",
    "# Creat the finances_need column (missing in the data) based on finances_perception\n",
    "def map_finances_perception_to_need(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    text = str(text).lower()\n",
    "    if any(kw in text for kw in [\"ideal\", \"adequate\"]):\n",
    "        return 0\n",
    "    elif any(kw in text for kw in [\"some\", \"often\", \"high need\", \"struggle\", \"debt\", \"bills\", \"money\"]):\n",
    "        return 1\n",
    "    else:\n",
    "        return None  # Ambiguous or \"Other\"\n",
    "    \n",
    "snap_subset[\"finances_need\"] = snap_subset[\"finances_perception\"].apply(map_finances_perception_to_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a21c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 2: Monitoring inconsistencies in the structured data collection ---\n",
    "from src.data_cleaning.data_cleaning_helpers import flag_snap_inconsistencies\n",
    "\n",
    "# Create columns to flag inconsistencies in SDoH perception and need columns\n",
    "snap_subset = flag_snap_inconsistencies(snap_subset, perception_col=\"food_perception\", need_col=\"food_insecurity_need\", label=\"food\")\n",
    "snap_subset = flag_snap_inconsistencies(snap_subset, \"housing_perception\", \"housing_need\", \"housing\")\n",
    "snap_subset = flag_snap_inconsistencies(snap_subset, \"social_perception\", \"loneliness_need\", \"loneliness\")\n",
    "\n",
    "# Create a single column for whether any flag exists\n",
    "flag_cols = [\"food_need_flag\", \"housing_need_flag\", \"loneliness_need_flag\"]\n",
    "snap_subset[\"any_inconsistency\"] = snap_subset[flag_cols].notna().any(axis=1)\n",
    "\n",
    "# Filter to just inconsistent cases\n",
    "inconsistent_subset = snap_subset[snap_subset[\"any_inconsistency\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040f1c6",
   "metadata": {},
   "source": [
    "Visual inspection, cross-checking structured data with the referrals, reveals that neither perception nor binary need column types are fully reliable. Tge decision is therefore to exclude all rows which display an inconsistency in their structured data (7%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd40338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: Final wrap-up ---\n",
    "# Drop rows that meet any of the following exclusion criteria:\n",
    "# - Missing referral_note\n",
    "# - Inconsistency in food, housing, or loneliness domain\n",
    "# - has_valid_baseline is False\n",
    "flag_cols = [\"food_need_flag\", \"housing_need_flag\", \"loneliness_need_flag\"]\n",
    "\n",
    "snap_final_df = snap_subset[\n",
    "    snap_subset[\"referral_note\"].notna() &\n",
    "    snap_subset[\"has_valid_baseline\"].astype(bool) &\n",
    "    (~snap_subset[\"any_inconsistency\"])\n",
    "].copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [col for col in snap_final_df.columns if \"flag\" in col or \"inconsistency\" in col]\n",
    "snap_final_df = snap_final_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Save final cleaned SNAP dataset\n",
    "snap_final_df.to_csv(\"../data/processed/brc-cleaned/snap_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a595c9",
   "metadata": {},
   "source": [
    "### 2.2. HIU final cleaning\n",
    "\n",
    "The HIU dataset was cleaned and filtered to support analysis of social determinants of health (SDoH). Key steps:\n",
    "\n",
    "1. **Domain Selection**: We focused on three SDoH domains:\n",
    "   - Housing\n",
    "   - Finances\n",
    "   - Loneliness\n",
    "\n",
    "2. **Label Construction**:\n",
    "   - For service users with only **1 assessment** (`num_assessments = 1`), we used the level variables:\n",
    "     - `Housing level`, `Finance level`, `Loneliness Level`\n",
    "   - For users with **2 or more assessments**, we inferred the baseline state from the *left-hand side* of the change columns:\n",
    "     - `Housing Change`, `Finance Change`, `Loneliness Change`\n",
    "   - These values were mapped to binary need indicators: `0 = No Need`, `1 = Need`.\n",
    "\n",
    "3. **Perception Indicators**: We retained one perception variable per domain to support consistency checks:\n",
    "   - `Q10` for housing\n",
    "   - `Q11` for finances\n",
    "   - `Q9.6` for loneliness\n",
    "\n",
    "4. **Exclusion Criteria**: Rows were dropped if:\n",
    "   - `referral_note` was missing\n",
    "   - The row contained inconsistency between perception and binary need\n",
    "   - No valid baseline assessment was available\n",
    "\n",
    "5. **Final Output**: The resulting `hiu_final.csv` contains reliable binary labels for each domain, aligned with referral content and baseline assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896e61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean\n",
    "merged_hiu_df = pd.read_csv(\"../data/processed/merged/merged_referrals_hiu.csv\")\n",
    "merged_hiu_df.columns = merged_hiu_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54ff695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 1: Subsetting columns ---\n",
    "referral_col = {\n",
    "    \"Referral Notes (depersonalised)\": \"referral_note\"\n",
    "}\n",
    "\n",
    "level_cols = {\n",
    "    \"Housing level\": \"housing_need\",\n",
    "    \"Finance level\": \"finances_need\",\n",
    "    \"Loneliness Level\": \"loneliness_need\"\n",
    "}\n",
    "\n",
    "qual_change_cols = {\n",
    "    \"Housing Change\": \"housing_qual_change\",\n",
    "    \"Finance Change\": \"finances_qual_change\",\n",
    "    \"Loneliness Change\": \"loneliness_qual_change\"\n",
    "}\n",
    "\n",
    "quant_change_cols = {\n",
    "    \"Change in Housing\": \"housing_quant_change\",\n",
    "    \"Change in Finance\": \"finances_quant_change\",\n",
    "    \"Change in Loneliness\": \"loneliness_quant_change\",\n",
    "}\n",
    "\n",
    "perception_cols = {\n",
    "    \"Q10. Which of the following best describe your current home/housing situation?\": \"housing_perception\",\n",
    "    \"Q11. What best describes your current financial situation?\": \"finances_perception\",\n",
    "    \"Q9.6. Iâ€™ve been feeling close to other people\": \"loneliness_perception\"\n",
    "}\n",
    "\n",
    "# !! Cannot use 'has_valid_baseline' because cases with only baseline have it as False (due to creation of this variable in the pre-cleaning step)\n",
    "meta_cols = [\"case_ref\", \"num_assessments\"]\n",
    "\n",
    "hiu_subset = merged_hiu_df[\n",
    "    meta_cols + list(referral_col.keys()) + list(level_cols.keys()) + \n",
    "    list(qual_change_cols.keys()) + list(quant_change_cols.keys()) + list(perception_cols.keys())\n",
    "].copy()\n",
    "\n",
    "hiu_subset = hiu_subset.rename(columns={**referral_col, **level_cols, **qual_change_cols, **quant_change_cols, **perception_cols})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a1aa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2055231/1983923106.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  hiu_subset[level_col] = hiu_subset[f\"{level_col}_tmp\"].replace(need_map).infer_objects(copy=False)\n",
      "/tmp/ipykernel_2055231/1983923106.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  hiu_subset[level_col] = hiu_subset[f\"{level_col}_tmp\"].replace(need_map).infer_objects(copy=False)\n",
      "/tmp/ipykernel_2055231/1983923106.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  hiu_subset[level_col] = hiu_subset[f\"{level_col}_tmp\"].replace(need_map).infer_objects(copy=False)\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 2: Compute binary need from level and qualitative change ---\n",
    "def extract_baseline_from_change(change_str):\n",
    "    if pd.isna(change_str):\n",
    "        return None\n",
    "    return change_str.split(\"-\")[0].strip()\n",
    "\n",
    "need_map = {\n",
    "    \"Housing Need\": 1, \"No Housing Need\": 0,\n",
    "    \"Finance Need\": 1, \"No finance need\": 0,\n",
    "    \"Lonely\": 1, \"Not lonely\": 0\n",
    "}\n",
    "\n",
    "for domain in [\"housing\", \"finances\", \"loneliness\"]:\n",
    "    level_col = f\"{domain}_need\"\n",
    "    qual_col = f\"{domain}_qual_change\"\n",
    "    hiu_subset[f\"{level_col}_tmp\"] = None\n",
    "\n",
    "    hiu_subset.loc[hiu_subset[\"num_assessments\"] == 1, f\"{level_col}_tmp\"] = hiu_subset.loc[\n",
    "        hiu_subset[\"num_assessments\"] == 1, level_col\n",
    "    ]\n",
    "    hiu_subset.loc[hiu_subset[\"num_assessments\"] > 1, f\"{level_col}_tmp\"] = hiu_subset.loc[\n",
    "        hiu_subset[\"num_assessments\"] > 1, qual_col\n",
    "    ].apply(extract_baseline_from_change)\n",
    "\n",
    "    hiu_subset[level_col] = hiu_subset[f\"{level_col}_tmp\"].replace(need_map).infer_objects(copy=False)\n",
    "\n",
    "# Drop intermediate tmp columns\n",
    "hiu_subset = hiu_subset.drop(columns=[col for col in hiu_subset.columns if col.endswith(\"_tmp\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ffe098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 3: Compute baseline perceptions (final-quant change) ---\n",
    "for domain in [\"housing\", \"finances\", \"loneliness\"]:\n",
    "    final = f\"{domain}_perception\"\n",
    "    change = f\"{domain}_quant_change\"\n",
    "    baseline = f\"{domain}_perception_baseline\"\n",
    "\n",
    "    hiu_subset[baseline] = hiu_subset[final] - hiu_subset[change]\n",
    "\n",
    "# Add baseline perceptions for cases with only baseline assessment\n",
    "# These cases have num_assessments == 1, so we can directly use the perception\n",
    "for domain in [\"housing\", \"finances\", \"loneliness\"]:\n",
    "    hiu_subset.loc[\n",
    "        hiu_subset[\"num_assessments\"] == 1,\n",
    "        f\"{domain}_perception_baseline\"\n",
    "    ] = hiu_subset.loc[\n",
    "        hiu_subset[\"num_assessments\"] == 1,\n",
    "        f\"{domain}_perception\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0815ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STEP 4: Final filtering ---\n",
    "# Only keep valid referrals + at least one known need\n",
    "need_cols = [\"housing_need\", \"finances_need\", \"loneliness_need\"]\n",
    "hiu_final_df = hiu_subset[\n",
    "    hiu_subset[\"referral_note\"].notna() &\n",
    "    hiu_subset[need_cols].notna().any(axis=1)\n",
    "].drop_duplicates(\"case_ref\")\n",
    "\n",
    "# Save final cleaned HIU dataset\n",
    "hiu_final_df.to_csv(\"../data/processed/brc-cleaned/hiu_final.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
