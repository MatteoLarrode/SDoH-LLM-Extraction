{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e413d4d",
   "metadata": {},
   "source": [
    "# Annotation & inter-annotator agreement analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6cf3e",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c7d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38c32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd8299",
   "metadata": {},
   "source": [
    "## 1. Create sentence JSON for label-studio annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/keble8263-sdoh-extraction/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the cleaned referrals dataset\n",
    "referrals_df = pd.read_csv(\"../data/processed/brc-cleaned/referrals_cleaned.csv\")\n",
    "\n",
    "# Load spaCy model and add sentencizer\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"tagger\"])\n",
    "if not nlp.has_pipe(\"sentencizer\"):\n",
    "    nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Drop rows with missing notes and select relevant columns\n",
    "referrals_clean = referrals_df.dropna(subset=[\"Referral Notes (depersonalised)\"])[[\"Case Reference\", \"Referral Notes (depersonalised)\"]]\n",
    "\n",
    "# Ensure column names are valid Python identifiers\n",
    "referrals_clean.columns = [\"Case_Reference\", \"Referral_Notes\"]\n",
    "\n",
    "# Sentence splitting\n",
    "def extract_sentences(row):\n",
    "    doc = nlp(row.Referral_Notes)\n",
    "    return [\n",
    "        {\"data\": {\"text\": sent.text.strip()}, \"meta\": {\"case_reference\": row.Case_Reference}}\n",
    "        for sent in doc.sents\n",
    "        if len(sent.text.strip().split()) >= 3\n",
    "    ]\n",
    "\n",
    "# Process all rows\n",
    "tasks = [task for row in referrals_clean.itertuples(index=False, name=\"Row\") for task in extract_sentences(row)]\n",
    "\n",
    "# Deduplicate by text\n",
    "seen = set()\n",
    "unique_tasks = []\n",
    "for task in tasks:\n",
    "    txt = task[\"data\"][\"text\"]\n",
    "    if txt not in seen:\n",
    "        seen.add(txt)\n",
    "        unique_tasks.append(task)\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"../data/processed/annotations/referral_sentences_for_annotation.json\", \"w\") as f:\n",
    "    json.dump(unique_tasks, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d13b59",
   "metadata": {},
   "source": [
    "## 2. Cross-annotation round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562a255",
   "metadata": {},
   "source": [
    "### 2.1. Create two lists of sentences to be cross-annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "INPUT_FILE = \"../data/raw/Label-studio/label-studio-annotations-2025-06-26.json\"\n",
    "OUTPUT_CAT = \"../data/processed/annotations/round1/BRC_Cat_annotation.csv\"\n",
    "OUTPUT_MAIWENN = \"../data/processed/annotations/round1/BRC_Maiwenn_annotation.csv\"\n",
    "SAMPLE_SIZE = 200\n",
    "SEED = 42\n",
    "\n",
    "# Load exported data\n",
    "with open(INPUT_FILE, \"r\") as f:\n",
    "    tasks = json.load(f)\n",
    "\n",
    "# Helper: check if task is only No SDoH\n",
    "def is_only_no_sdoh(annotations):\n",
    "    for ann in annotations:\n",
    "        for r in ann.get(\"result\", []):\n",
    "            if r.get(\"from_name\") != \"no_sdoh\" or \"True\" not in r.get(\"value\", {}).get(\"choices\", []):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# Filter and sample\n",
    "sdoh_sentences = [\n",
    "    task[\"data\"][\"text\"].strip()\n",
    "    for task in tasks\n",
    "    if not is_only_no_sdoh(task.get(\"annotations\", []))\n",
    "]\n",
    "\n",
    "random.seed(SEED)\n",
    "sampled = random.sample(sdoh_sentences, min(SAMPLE_SIZE, len(sdoh_sentences)))\n",
    "\n",
    "# Split and save\n",
    "mid = len(sampled) // 2\n",
    "pd.DataFrame(sampled[:mid], columns=[\"Sentence\"]).to_csv(OUTPUT_CAT, index=False)\n",
    "pd.DataFrame(sampled[mid:], columns=[\"Sentence\"]).to_csv(OUTPUT_MAIWENN, index=False)\n",
    "\n",
    "print(f\"âœ… Created '{OUTPUT_CAT}' and '{OUTPUT_MAIWENN}' with {mid} sentences each.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7858676c",
   "metadata": {},
   "source": [
    "### 2.2. Compare my annotations to BRC staff annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.annotation.parse_annotations_helpers import parse_labelstudio_json, parse_csv_annotations\n",
    "\n",
    "round1_labelstudio_path = \"../data/processed/annotations/label-studio/label-studio-annotations-2025-06-26-round1.json\"\n",
    "round1_BRC_Cat_annotation_path = \"../data/processed/annotations/round1/BRC_Cat_annotation_completed.csv\"\n",
    "\n",
    "# Parse my Label Studio JSON annotations for round 1\n",
    "parsed_annotations_round1_df = parse_labelstudio_json(round1_labelstudio_path)\n",
    "\n",
    "# Parse BRC staff annotations for round 1\n",
    "parsed_CAT_annotations_round1_df = parse_csv_annotations(round1_BRC_Cat_annotation_path, \"BRC_Cat\")\n",
    "\n",
    "# Get list of cross-annotated sentences (those Cat labeled)\n",
    "cross_sentences = parsed_CAT_annotations_round1_df[\"Sentence\"].unique()\n",
    "\n",
    "# Filter both DataFrames to just those sentences\n",
    "parsed_annotations_round1_filtered_df = parsed_annotations_round1_df[parsed_annotations_round1_df[\"Sentence\"].isin(cross_sentences)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14abc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.annotation.cross_annotation_helpers import compare_annotations_krippendorff, compute_classwise_krippendorff\n",
    "\n",
    "# Get mismatches\n",
    "alpha, mismatches = compare_annotations_krippendorff(parsed_annotations_round1_filtered_df, parsed_CAT_annotations_round1_df)\n",
    "\n",
    "# Compute classwise Krippendorff's alpha\n",
    "alpha_df = compute_classwise_krippendorff(\n",
    "    parsed_annotations_round1_filtered_df,\n",
    "    parsed_CAT_annotations_round1_df,\n",
    "    save_latex=True,\n",
    "    latex_path=\"../results/latex_tables/classwise_krippendorff_round1.tex\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
