{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e413d4d",
   "metadata": {},
   "source": [
    "# Curation and creation of data for LLM finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6cf3e",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c7d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38c32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Add the project root to the Python path to import the modules\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cd8299",
   "metadata": {},
   "source": [
    "## 1. Curation from manually annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19040f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.annotation.parse_annotations_helpers import parse_labelstudio_json\n",
    "\n",
    "round1_labelstudio_path = \"../data/processed/annotations/label-studio/label-studio-annotations-2025-06-26-round1.json\"\n",
    "\n",
    "from src.classification.prompt_creation_helpers import create_automated_prompt\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# === Step 1: Load long-form parsed annotations ===\n",
    "df = parse_labelstudio_json(round1_labelstudio_path)\n",
    "\n",
    "# Drop incomplete rows\n",
    "df = df[df[\"SDoH\"].notnull() & df[\"Polarity\"].notnull()]\n",
    "df = df[df[\"SDoH\"].str.strip() != \"\"]\n",
    "\n",
    "# === Step 2: Group SDoH-Polarity pairs per sentence ===\n",
    "def format_label(sdoh, polarity):\n",
    "    return f\"{sdoh.strip()}-{polarity.strip()}\"\n",
    "\n",
    "df[\"label_pair\"] = df.apply(lambda row: format_label(row[\"SDoH\"], row[\"Polarity\"]), axis=1)\n",
    "\n",
    "grouped = (\n",
    "    df.groupby(\"Sentence\")[\"label_pair\"]\n",
    "    .apply(lambda labels: \"<LIST>\" + \", \".join(sorted(set(labels))) + \"</LIST>\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"label_pair\": \"completion\"})\n",
    ")\n",
    "\n",
    "# === Step 3: Generate prompts\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "grouped[\"prompt\"] = grouped[\"Sentence\"].apply(\n",
    "    lambda s: create_automated_prompt(s, tokenizer=tokenizer, prompt_type=\"five_shot_basic\")\n",
    ")\n",
    "\n",
    "# === Step 4: Final dataset\n",
    "finetune_dataset = Dataset.from_pandas(grouped[[\"prompt\", \"completion\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa5b462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are analyzing a referral note sentence to identify Social Determinants of Health, and classifying them as Adverse or Protective.\n",
      "\n",
      "Given a sentence, output all SDoH factors that can be inferred from that sentence from the following list: \n",
      "Loneliness, Housing, Finances, FoodAccess, Digital, Employment, EnglishProficiency.\n",
      "\n",
      "Each SDoH must be classified as either \"Adverse\" or \"Protective\". \n",
      "If the sentence does NOT mention any of the above categories, output <LIST>NoSDoH</LIST>.\n",
      "\n",
      "Your response must be a comma-separated list of SDoH-Polarity pairs embedded in <LIST> and </LIST> tags.\n",
      "\n",
      "**STRICT RULES**:\n",
      "- DO NOT generate any other text, explanations, or new SDoH labels.\n",
      "- A sentence CAN be labeled with one or more SDoH factors.\n",
      "- The only accepted format is <LIST>...</LIST>.\n",
      "\n",
      "EXAMPLES:\n",
      "Input: \"She is unemployed and struggles to pay rent.\"\n",
      "Output: <LIST>Employment-Adverse, Finances-Adverse, Housing-Adverse</LIST>\n",
      "\n",
      "Input: \"We are referring the above patient to you today for befriending.\"\n",
      "Output: <LIST>Loneliness-Adverse</LIST>\n",
      "\n",
      "Input: \"She enjoys a strong network of friends and volunteers weekly.\"\n",
      "Output: <LIST>Loneliness-Protective</LIST>\n",
      "\n",
      "Input: \"Sleeping at a friend's for now.\"\n",
      "Output: <LIST>Housing-Adverse</LIST>\n",
      "\n",
      "Input: \"Cannot take public transport to do groceries.\"\n",
      "Output: <LIST>FoodAccess-Adverse</LIST>\n",
      "\n",
      "Input: \"Daughter translates at GP visits.\"\n",
      "Output: <LIST>EnglishProficiency-Adverse</LIST><|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Input: \"-Befriending Visits * Fall with head injury * Lives alone with no family or close friends , reports feeling lonely and would like some company to interact with .\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "<LIST>Loneliness-Adverse</LIST>\n"
     ]
    }
   ],
   "source": [
    "# Output example\n",
    "print(finetune_dataset[0][\"prompt\"])\n",
    "print(finetune_dataset[0][\"completion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d13b59",
   "metadata": {},
   "source": [
    "## 2. Creation of synthetic data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keble8263-sdoh-extraction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
